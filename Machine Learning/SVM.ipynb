{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the wine dataset using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(wine['data'], wine['target'], random_state=2501)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing US postal service training and test set and combining them into USPS and then using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "USPS_traindata = np.genfromtxt(\"zip.train\", delimiter=\" \")\n",
    "USPS_testdata = np.genfromtxt(\"zip.test\", delimiter=\" \")\n",
    "USPS = np.append(USPS_traindata,USPS_testdata, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = USPS[:,1:257]\n",
    "target = USPS[:,0]\n",
    "Xu_train,Xu_test,yu_train,yu_test = train_test_split(data,target, random_state=2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cross validation scores for wine training datset with 5 folds is  [0.7037037  0.7037037  0.66666667 0.69230769 0.73076923]\n",
      "the cross validation scores for USPS training datset with 5 folds is  [0.96487455 0.96917563 0.96774194 0.97274032 0.97274032]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svmW = SVC()\n",
    "scoresw = cross_val_score(svmW, Xw_train, yw_train)\n",
    "\n",
    "svmU = SVC()\n",
    "scoresu = cross_val_score(svmU, Xu_train, yu_train )\n",
    "\n",
    "print(\"the cross validation scores for wine training datset with 5 folds is \", scoresw)\n",
    "print(\"the cross validation scores for USPS training datset with 5 folds is \", scoresu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test error rate for wine dataset with default values of parameter for SVM is  0.3111111111111111\n",
      "the test error rate for USPS dataset with default values of parameter for SVM is  0.023655913978494647\n"
     ]
    }
   ],
   "source": [
    "svmW.fit(Xw_train,yw_train)\n",
    "print(\"the test error rate for wine dataset with default values of parameter for SVM is \",1 - svmW.score(Xw_test,yw_test))\n",
    "svmU.fit(Xu_train,yu_train)\n",
    "print(\"the test error rate for USPS dataset with default values of parameter for SVM is \",1 - svmU.score(Xu_test,yu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score for wine dataset was lower than expected in the range (66 to 73), so the test error rate was expected to be higher, which in this case is 31%. The same is not true for USPS dataset, the cross validation scores were high enough ( in the range of 96-98) so in turn we had a very little error rate of 2%. Hence, the test error rate not only depends on the model used but the training data used as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pipeNormalizer = [StandardScaler(), MinMaxScaler(), RobustScaler(), Normalizer()]\n",
    "parameters = {'svc__C':[0.01, 0.1, 1, 10], 'svc__gamma': [0.01, 0.1, 1, 10 ]}\n",
    "\n",
    "best_score_w = 0\n",
    "best_score_u = 0 \n",
    "\n",
    "for i in pipeNormalizer:\n",
    "    \n",
    "    print(\"using the normalizer: \", i)\n",
    "    pipe =  make_pipeline(i, SVC())\n",
    "    print(\"pipe created: \",i)\n",
    "    gridw =  GridSearchCV(pipe, param_grid = parameters, cv=3, n_jobs = -1)\n",
    "    print(\"grid initialized for wine dataset\")\n",
    "    gridw.fit(Xw_train,yw_train)\n",
    "    print(\"fit to train set complete for wine dataset\")\n",
    "    \n",
    "    if gridw.best_score_ > best_score_w:\n",
    "        best_score_w = gridw.best_score_\n",
    "        best_normalizer_w = i\n",
    "        best_param_w = gridw.best_params_\n",
    "        best_fit_w = gridw\n",
    "        print(\"the current best score for wine dataset is\",best_score_w)\n",
    "    \n",
    "    \n",
    "    gridu =  GridSearchCV(pipe, param_grid = parameters, cv=3, n_jobs = -1)\n",
    "    print(\"grid initialized for USPS dataset\")\n",
    "    gridu.fit(Xu_train,yu_train)\n",
    "    print(\"fit to train set complete for USPS dataset\")\n",
    "    \n",
    "    if gridu.best_score_ > best_score_u:\n",
    "        best_score_u = gridu.best_score_\n",
    "        best_normalizer_u = i\n",
    "        best_param_u = gridu.best_params_\n",
    "        best_fit_u = gridu\n",
    "        print(\"the current best score for USPS dataset is\",best_score_u)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Wine dataset, the best score was  0.9848484848484849  with the parameters  {'svc__C': 10, 'svc__gamma': 0.1}  and using the normalizer:  StandardScaler()\n",
      "For USPS dataset, the best score was  0.9716046366726507 with the parameters: {'svc__C': 10, 'svc__gamma': 1} and using normalizer: Normalizer()\n"
     ]
    }
   ],
   "source": [
    "print(\"For Wine dataset, the best score was \",best_score_w,\" with the parameters \" ,best_param_w ,\" and using the normalizer: \",best_normalizer_w)\n",
    "\n",
    "print(\"For USPS dataset, the best score was \",best_score_u,\"with the parameters:\",best_param_u,\"and using normalizer:\",best_normalizer_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for wine dataset, it would be better if we use Standard Scalar with Parameter C=10 and gamma=0.1\n",
    "and for USPS dataset, the Normalizer scaling is better with the parameter C=10 and gamma=1\n",
    "although the results here are based on training set, we should also take a look at test error rate using these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "random.seed(2501)\n",
    "\n",
    "#finding other Normalizer\n",
    "if str(best_normalizer_w) == 'Normalizer()':\n",
    "    pipeNormalizerw = copy.copy(pipeNormalizer)\n",
    "    pipeNormalizerw.remove(best_normalizer_w)\n",
    "    anotherNormalizerw = pipeNormalizerw[random.randrange(0,len(pipeNormalizerw))]\n",
    "else:\n",
    "    anotherNormalizerw = Normalizer()\n",
    "\n",
    "# print(best_normalizer_w)\n",
    "# print(anotherNormalizerw)\n",
    "\n",
    "\n",
    "if str(best_normalizer_u) == 'Normalizer()':\n",
    "    pipeNormalizeru = copy.copy(pipeNormalizer)\n",
    "    pipeNormalizeru.remove(best_normalizer_u)\n",
    "    anotherNormalizeru = pipeNormalizeru[random.randrange(0,len(pipeNormalizeru))]\n",
    "else:\n",
    "    anotherNormalizeru = Normalizer()\n",
    "\n",
    "# #type(best_normalizer_u)\n",
    "# print(best_normalizer_u)\n",
    "# print(anotherNormalizeru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(C=10, gamma=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test error rate using score\n",
    "\n",
    "anotherpipew = make_pipeline(anotherNormalizerw,SVC(C=best_param_w[\"svc__C\"], gamma = best_param_w[\"svc__gamma\"]))\n",
    "anotherpipeu = make_pipeline(anotherNormalizeru,SVC(C=best_param_u[\"svc__C\"], gamma = best_param_u[\"svc__gamma\"]))\n",
    "\n",
    "anotherpipew.fit(Xw_train,yw_train)\n",
    "anotherpipeu.fit(Xu_train,yu_train)\n",
    "\n",
    "# score_w=anotherpipew.score(Xw_test,yw_test) \n",
    "# score_u=anotherpipeu.score(Xu_test,yu_test)\n",
    "\n",
    "# best_test_w = best_fit_w.score(Xw_test,yw_test)\n",
    "# best_test_u = best_fit_u.score(Xu_test,yu_test)\n",
    "\n",
    "# print(\"For Wine dataset: \\n for the given set of parameters and normalizer \\n Normalizer:\",anotherNormalizerw,\"\\n Parameter:\",best_param_w,\"\\n the test error rate is:\", 1-score_w,end='\\n')\n",
    "# print(\"For Wine dataset with \\n best Normalizer:\",best_normalizer_w,\"\\n best Parameter:\",best_param_w,\"\\n test error rate is :\", 1-best_test_w, end = '\\n\\n')\n",
    "\n",
    "# print(\"For USPS dataset: \\n for the given set of parameters and normalizer \\n Normalizer:\",anotherNormalizeru,\"\\n Parameter:\",best_param_u,\"\\n the test error rate is:\", 1-score_u,end = '\\n')\n",
    "# print(\"For USPS dataset with \\n best Normalizer:\",best_normalizer_u,\"\\n best Parameter:\",best_param_u,\"\\n test error rate is :\", 1-best_test_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Wine dataset: \n",
      " for the given set of parameters and normalizer \n",
      " Normalizer: Normalizer() \n",
      " Parameter: {'svc__C': 10, 'svc__gamma': 0.1} \n",
      " the test error rate is: 0.6222222222222222\n",
      "For Wine dataset with \n",
      " best Normalizer: StandardScaler() \n",
      " best Parameter: {'svc__C': 10, 'svc__gamma': 0.1} \n",
      " test error rate is : 0.022222222222222223\n",
      "\n",
      "For USPS dataset: \n",
      " for the given set of parameters and normalizer \n",
      " Normalizer: StandardScaler() \n",
      " Parameter: {'svc__C': 10, 'svc__gamma': 1} \n",
      " the test error rate is: 0.792258064516129\n",
      "For USPS dataset with \n",
      " best Normalizer: Normalizer() \n",
      " best Parameter: {'svc__C': 10, 'svc__gamma': 1} \n",
      " test error rate is : 0.021075268817204302\n"
     ]
    }
   ],
   "source": [
    "#test error rate using the predicted values:\n",
    "\n",
    "best_pred_w = best_fit_w.predict(Xw_test)\n",
    "best_pred_u = best_fit_u.predict(Xu_test)\n",
    "\n",
    "another_pred_w = anotherpipew.predict(Xw_test)\n",
    "another_pred_u = anotherpipeu.predict(Xu_test)\n",
    "\n",
    "testErrorw = sum(yw_test != best_pred_w)/len(yw_test)\n",
    "testErroru = sum(yu_test != best_pred_u)/len(yu_test)\n",
    "\n",
    "anotherTestErrorw = sum(yw_test != another_pred_w)/len(yw_test)\n",
    "anotherTestErroru = sum(yu_test != another_pred_u)/len(yu_test)\n",
    "\n",
    "print(\"For Wine dataset: \\n for the given set of parameters and normalizer \\n Normalizer:\",anotherNormalizerw,\"\\n Parameter:\",best_param_w,\"\\n the test error rate is:\",anotherTestErrorw ,end='\\n')\n",
    "print(\"For Wine dataset with \\n best Normalizer:\",best_normalizer_w,\"\\n best Parameter:\",best_param_w,\"\\n test error rate is :\",testErrorw , end = '\\n\\n')\n",
    "\n",
    "print(\"For USPS dataset: \\n for the given set of parameters and normalizer \\n Normalizer:\",anotherNormalizeru,\"\\n Parameter:\",best_param_u,\"\\n the test error rate is:\",anotherTestErroru ,end = '\\n')\n",
    "print(\"For USPS dataset with \\n best Normalizer:\",best_normalizer_u,\"\\n best Parameter:\",best_param_u,\"\\n test error rate is :\",testErroru )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test error rate with the Normalizer seems too high for wine dataset but better for USPS dataset.\n",
    "This is completely opposite for USPS dataset where Standard Scalar yeilds high test error rate as compared to Normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-conformal predictor partially implemented.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(shuffle=True, random_state=2501) # default n_splits is 5\n",
    "\n",
    "pipew = make_pipeline(best_normalizer_w, SVC(C=best_param_w[\"svc__C\"], gamma=best_param_w[\"svc__gamma\"]))\n",
    "pipeu = make_pipeline(best_normalizer_u, SVC(C=best_param_u[\"svc__C\"], gamma=best_param_u[\"svc__gamma\"]))\n",
    "\n",
    "\n",
    "conformalScorew = list()\n",
    "conformalScoreu = list()\n",
    "rankw = 0\n",
    "\n",
    "#for wine dataset:\n",
    "for rest_index, fold_index in kf.split(Xw_train):\n",
    "    Xw_rest, Xw_fold = Xw_train[rest_index], Xw_train[fold_index]\n",
    "    yw_rest, yw_fold = yw_train[rest_index], yw_train[fold_index]\n",
    "    pipew.fit(Xw_rest, yw_rest)\n",
    "    XaugmentedFold = np.append(Xw_fold, Xw_test, axis = 0)\n",
    "    #yaugmentedFold= np.append(yw_fold,yw_test, axis = 0)\n",
    "    #conw = pipew.decision_function(XaugmentedFold)\n",
    "\n",
    "    icmTestw = pipew.decision_function(Xw_test)\n",
    "    icmFoldw = pipew.decision_function(Xw_fold)\n",
    "    \n",
    "    #to find p(y)\n",
    "    #apply decision function on pipew and fold to find (a i,k) and apply the decision function on pipew to find (a^yk)\n",
    "    #we then use the two values we do for each fold sum of  rank of aik < a^yk +1 /n+1\n",
    "    \n",
    "    #also need to figure out how to compute the rank of test sample in each fold and subtract 1 to get pythonic rank.\n",
    "\n",
    "    #conformalScorew.extend(conw)\n",
    "\n",
    "# print(len(conformalScorew))\n",
    "# print(len(yw_test)*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cross validation scores for wine training datset with 5 folds is  [0.2962963  0.48148148 0.40740741 0.46153846 0.19230769]\n",
      "the cross validation scores for USPS training datset with 5 folds is  [0.96057348 0.96344086 0.94982079 0.96987088 0.96628407]\n"
     ]
    }
   ],
   "source": [
    "#running MLPClassifier with crossValidation of cv=5(default) and with default Parameters\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "mlpW = MLPClassifier()\n",
    "scoresw = cross_val_score(mlpW, Xw_train, yw_train)\n",
    "\n",
    "mlpU = MLPClassifier()\n",
    "scoresu = cross_val_score(mlpU, Xu_train, yu_train )\n",
    "\n",
    "print(\"the cross validation scores for wine training datset with 5 folds is \", scoresw)\n",
    "print(\"the cross validation scores for USPS training datset with 5 folds is \", scoresu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test error rate for wine dataset with default values of parameter for SVM is  0.24444444444444446\n",
      "the test error rate for USPS dataset with default values of parameter for SVM is  0.029247311827957034\n"
     ]
    }
   ],
   "source": [
    "mlpW.fit(Xw_train,yw_train)\n",
    "print(\"the test error rate for wine dataset with default values of parameter for SVM is \",1 - mlpW.score(Xw_test,yw_test))\n",
    "mlpU.fit(Xu_train,yu_train)\n",
    "print(\"the test error rate for USPS dataset with default values of parameter for SVM is \",1 - mlpU.score(Xu_test,yu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting warning that the optimization hasn't converged yet for few of the initial runs of iteration. The algorithm is optimizing by a stepwise convergence to a minimum and in these initial run, minimum wasn't found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again, the cross validation score for wine dataset had most of the scores too low and hence the test error rate was expected to be high. Although USPS dataset with the cross validation score was having good score overall and hence the value for test error rate was also expected to be low. This observation is helpful to determine that it not only depends on the models use with different scaling and parameter but the dataset provided for training as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLPClassifier for the following values and dataset: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for wine dataset & Normalizer: StandardScaler() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.01, 'mlpclassifier__learning_rate': 'constant'} the best score is: 0.9924242424242425\n",
      "for USPS dataset & Normalizer: StandardScaler() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'invscaling'} the best score is: 0.9638604803237527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for wine dataset & Normalizer: MinMaxScaler() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'constant'} the best score is: 0.9848484848484849\n",
      "for USPS dataset & Normalizer: MinMaxScaler() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'adaptive'} the best score is: 0.9648646814600954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for wine dataset & Normalizer: RobustScaler() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'adaptive'} the best score is: 0.9924242424242425\n",
      "for USPS dataset & Normalizer: RobustScaler() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.0001, 'mlpclassifier__learning_rate': 'adaptive'} the best score is: 0.9426349946637549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for wine dataset & Normalizer: Normalizer() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'invscaling'} the best score is: 0.6617845117845117\n",
      "for USPS dataset & Normalizer: Normalizer() \n",
      " and with best parameters: {'mlpclassifier__alpha': 0.001, 'mlpclassifier__learning_rate': 'adaptive'} the best score is: 0.9568335399971623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#trying different parameters and normalizers with MLPClassifier\n",
    "\n",
    "pipeNormalizer = [StandardScaler(), MinMaxScaler(), RobustScaler(), Normalizer()]\n",
    "parameters = {'mlpclassifier__learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "              'mlpclassifier__alpha': 10.0 ** -np.arange(1, 5)\n",
    "             }\n",
    "\n",
    "print(\"Using MLPClassifier for the following values and dataset: \\n\")\n",
    "#list of fit to avoid refitting for calculating the test error rate\n",
    "fitListw = []\n",
    "fitListu = []\n",
    "\n",
    "for i in pipeNormalizer:\n",
    "    \n",
    "    pipe =  make_pipeline(i, MLPClassifier())\n",
    "    gridw =  GridSearchCV(pipe, param_grid = parameters, cv=3, n_jobs = -1)\n",
    "    gridw.fit(Xw_train,yw_train)\n",
    "     \n",
    "    print(\"for wine dataset & Normalizer:\",i,\"\\n and with best parameters:\",gridw.best_params_,\"the best score is:\",gridw.best_score_,end = '\\n')\n",
    "    fitListw.append(gridw)\n",
    "    \n",
    "    gridu =  GridSearchCV(pipe, param_grid = parameters, cv=3, n_jobs = -1)\n",
    "    gridu.fit(Xu_train,yu_train)\n",
    "    print(\"for USPS dataset & Normalizer:\",i,\"\\n and with best parameters:\",gridu.best_params_,\"the best score is:\",gridu.best_score_,end = '\\n')\n",
    "    fitListu.append(gridu)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MLPClassifier and wine dataset it seems either of the scaling method( Standard Scaler or robustScaler) is better suited with given training set.\n",
    "on the other hand, for USPS dataset MinMaxScalar yeilds the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Wine dataset and MLPClassifier : \n",
      " for the given set of parameters and normalizer \n",
      " Normalizer: StandardScaler() \n",
      " Parameter: {'mlpclassifier__alpha': 0.01, 'mlpclassifier__learning_rate': 'constant'} \n",
      " the test error rate is: 0.0\n",
      "For Wine dataset and MLPClassifier: \n",
      " for the given set of parameters and normalizer \n",
      " Normalizer: Normalizer() \n",
      " best Parameter: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'invscaling'} \n",
      " test error rate is : 0.37777777777777777\n",
      "\n",
      "For USPS dataset and MLPClassifier : \n",
      " for the given set of parameters and normalizer \n",
      " Normalizer: MinMaxScaler() \n",
      " Parameter: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'constant'} \n",
      " the test error rate is: 0.03096774193548387\n",
      "For USPS dataset and MLPClassifier: \n",
      " for the given set of parameters and normalizer \n",
      " Normalizer: Normalizer() \n",
      " best Parameter: {'mlpclassifier__alpha': 0.1, 'mlpclassifier__learning_rate': 'invscaling'} \n",
      " test error rate is : 0.03354838709677419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test error rate using predicted values\n",
    "\n",
    "pred_w1 = fitListw[0].predict(Xw_test)\n",
    "pred_w2 = fitListw[3].predict(Xw_test)\n",
    "\n",
    "pred_u1 = fitListu[1].predict(Xu_test)\n",
    "pred_u2 = fitListu[3].predict(Xu_test)\n",
    "\n",
    "testErrorw1 = sum(yw_test != pred_w1)/len(yw_test)\n",
    "testErroru1 = sum(yu_test != pred_u1)/len(yu_test)\n",
    "\n",
    "testErrorw2 = sum(yw_test != pred_w2)/len(yw_test)\n",
    "testErroru2 = sum(yu_test != pred_u2)/len(yu_test)\n",
    "\n",
    "print(\"For Wine dataset and MLPClassifier : \\n for the given set of parameters and normalizer \\n Normalizer:\",pipeNormalizer[0],\"\\n Parameter:\",fitListw[0].best_params_,\"\\n the test error rate is:\",testErrorw1 ,end='\\n')\n",
    "print(\"For Wine dataset and MLPClassifier: \\n for the given set of parameters and normalizer \\n Normalizer:\",pipeNormalizer[3],\"\\n best Parameter:\",fitListw[3].best_params_,\"\\n test error rate is :\",testErrorw2 , end = '\\n\\n')\n",
    "\n",
    "print(\"For USPS dataset and MLPClassifier : \\n for the given set of parameters and normalizer \\n Normalizer:\",pipeNormalizer[1],\"\\n Parameter:\",fitListw[1].best_params_,\"\\n the test error rate is:\",testErroru1 ,end='\\n')\n",
    "print(\"For USPS dataset and MLPClassifier: \\n for the given set of parameters and normalizer \\n Normalizer:\",pipeNormalizer[3],\"\\n best Parameter:\",fitListw[3].best_params_,\"\\n test error rate is :\",testErroru2 , end = '\\n\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
