{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1: Train a Sentiment Analysis Classifier\n",
    "In this course work, you are asked to train a sentiment analysis classifier for movie reviews. The sample code below builds a simple classifier that uses tf-idf to vectorize text and a logistic regression model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Enjoy the opening credits. They're the best th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, the Sci-Fi channel keeps churning these ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It takes guts to make a movie on Gandhi in Ind...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Nest is really just another 'nature run am...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Waco: Rules of Engagement does a very good job...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text sentiment\n",
       "0           0  Enjoy the opening credits. They're the best th...       neg\n",
       "1           1  Well, the Sci-Fi channel keeps churning these ...       neg\n",
       "2           2  It takes guts to make a movie on Gandhi in Ind...       pos\n",
       "3           3  The Nest is really just another 'nature run am...       neg\n",
       "4           4  Waco: Rules of Engagement does a very good job...       pos"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and take a quick look\n",
    "import pandas as pd\n",
    "raw_data = pd.read_csv('coursework1_train.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry num 40000\n",
      "num of pos entries 20000\n",
      "num of neg entries 20000\n"
     ]
    }
   ],
   "source": [
    "# check the size of the data and its class distribution\n",
    "all_text = raw_data['text'].tolist()\n",
    "all_lables = raw_data['sentiment'].tolist()\n",
    "\n",
    "print('entry num', len(all_text))\n",
    "print('num of pos entries', len([l for l in all_lables if l=='pos']))\n",
    "print('num of neg entries', len([l for l in all_lables if l=='neg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning and preprocessing:\n",
    "# This sample code does not perform any text normalization/pre-processing\n",
    "# Feel free to apply any pre-processing steps you find appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split. \n",
    "# Feel free to use differnt raios or strategies to split the data.\n",
    "train_text = all_text[:35000]\n",
    "train_labels = all_lables[:35000]\n",
    "test_text = all_text[35000:]\n",
    "test_labels = all_lables[35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8616\n",
      "precision 0.8616043455692743\n",
      "rec 0.8615913854621674\n",
      "f1 0.8615956596398864\n"
     ]
    }
   ],
   "source": [
    "# training: tf-idf + logistic regression\n",
    "# you should explore different representations and algorithms.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "max_feature_num = 1000\n",
    "train_vectorizer = TfidfVectorizer(max_features=max_feature_num)\n",
    "train_vecs = train_vectorizer.fit_transform(train_text)\n",
    "test_vecs = TfidfVectorizer(max_features=max_feature_num,vocabulary=train_vectorizer.vocabulary_).fit_transform(test_text)\n",
    "\n",
    "# train model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(train_vecs, train_labels)\n",
    "\n",
    "# test model\n",
    "test_pred = clf.predict(test_vecs)\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "print('acc', acc)\n",
    "print('precision', pre)\n",
    "print('rec', rec)\n",
    "print('f1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE YOUR TRAINED MODEL\n",
    "After you have found the best model, save your trained model and other necessary components (e.g. vocabulary, vectorizer) to a file. We will load your model from the saved file and apply your trained model on some held-out test data. **At submission time, you should submit the saved model file and we will NOT re-run your code to train your model; instead, we will directly use your trained model to run test (see notebook *cw1-test.ipynb*)**. \n",
    "\n",
    "Below is a sample code for saving the model (and other necessary components) obtained above, using the *pickle* package in Python. *You should adjust the code to save all the necessary components for re-running your model!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'model': clf,\n",
    "    'vectorizer': TfidfVectorizer(max_features=max_feature_num,vocabulary=train_vectorizer.vocabulary_)\n",
    "}\n",
    "\n",
    "with open(\"sample_trained_model.pickle\",\"wb\") as save_path:\n",
    "    pickle.dump(all_info_want_to_save, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *cw1-test.ipynb*, we provide a sample code to illustrate how to re-load your saved model and apply it to some test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "venv_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
