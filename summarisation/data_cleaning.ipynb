{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using CNN articles as dataset. These articles are stored in multiple files along with their highlights. These highlight can be used to gauge the summary output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try reading the file content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "text = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories/0a0a4c90d59df9e36ffec4ba306b4f20f3ba4acb.story')\n",
    "#text.split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the we need to do some cleaning before we start working on the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester United's Spaniards may have struggled to gel on the pitch, but they have been building up a close relationship off it.\n",
      "\n",
      "Juan Mata, Ander Herrera and David de Gea have become good friends and enjoyed lunch together in Hale Village, Cheshire on Tuesday afternoon.\n",
      "\n",
      "The Spanish trio were all named in Louis van Gaal's starting line-up for the opening day fixture against Swansea, although they were unable to prevent a disappointing 2-1 defeat bySwansea.\n",
      "\n",
      "VIDEO Scroll down to watch Mata challenge compatriot De Gea to Corner Kick Challenge \n",
      "\n",
      "Meet and greet: Juan Mata (left) has been helping fellow Spaniard Ander Herrera (right) settle in\n",
      "\n",
      "Join the club: Manchester United keeper David de Gea and Herrera pictured together on Tuesday\n",
      "\n",
      "Three Amigos: The Spaniards stroll down the high street as they enjoy an afternoon in Hale Village\n",
      "\n",
      "Van Gaal has brought another Spanish speaker to Old Trafford, with Argentina defender Marcos Rojo describing it as a 'dream' to play for the Old Trafford club.\n",
      "\n",
      "The Sporting Lisbon player has emerged has been a key summer target for Van Gaal and United have paid £16million for the defender and sent Portuguese winger Nani back to his former club on a one-year loan deal.\n",
      "\n",
      "In an interview with the radio station Continental, quoted in several national newspapers, Rojo said: 'It's a dream to play at Manchester United and I am very proud of having the chance of working with [Louis] van Gaal.\n",
      "\n",
      "'I spoke with Juan Sebastian Veron about Manchester United when we were at Estudiantes. I have always liked English football, and I should adapt to this new playing style easily.' \n",
      "\n",
      "Double act: Mata and Herrera are hoping to form a close-knit midfield partnership at Old Trafford\n",
      "\n",
      "Slow start: Mata and his United team-mates will be hoping for  improved performances after defeat by Swansea\n",
      "\n",
      "Dream move: Marcos Rojo (left) has signed for United from Sporting Lisbon for £16m\n",
      "\n",
      "VIDEO United reach deal for Rojo \n",
      "\n",
      "@highlight\n",
      "\n",
      "Manchester United's Spanish trio enjoyed lunch in Hale Village\n",
      "\n",
      "@highlight\n",
      "\n",
      "Mata, Herrera and De Gea pictured together on Tuesday afternoon\n",
      "\n",
      "@highlight\n",
      "\n",
      "All three players started in the opening day fixture with Swansea \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rohankilledar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    # cnn_indx = text.find(\"(CNN)\")\n",
    "    # if cnn_indx >=0:\n",
    "    #     text = text[cnn_indx+len(\"(CNN)\"):]\n",
    "        \n",
    "    #text = re.sub(\"\\n\",\" \",text).lower()\n",
    "\n",
    "    #text.split(\"\\n\")\n",
    "    # cleaned = list()\n",
    "    # table = str.maketrans('','',string.punctuation)\n",
    "\n",
    "    # for line in text:\n",
    "       \n",
    "    #     line = line.split(\" \")\n",
    "\n",
    "    #     line = [w.translate(table) for w in line]\n",
    "        \n",
    "    #     line = [w for w in line if w.isalpha()]\n",
    "    #     cleaned.append(' '.join(line))\n",
    "\n",
    "    # text = [sent for sent in cleaned if len(sent)>0]\n",
    "\n",
    "    return text\n",
    "\n",
    "article = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories/0a0a4c90d59df9e36ffec4ba306b4f20f3ba4acb.story')\n",
    "dmarticle = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/dailymail/stories/0a00a9aebcb754c51534867cf1db2335dcb76884.story')\n",
    "# t = article.split(\"\\n\")\n",
    "# cleaned = list()\n",
    "# table = str.maketrans('','',string.punctuation)\n",
    "# for w in t:\n",
    "#     if len(w)>0:\n",
    "#         w = w.split(\" \")\n",
    "#         w = [word.translate(table) for word in w]\n",
    "#         w = [word for word in w if word.isalpha()]\n",
    "#         cleaned.append(\" \".join(w))\n",
    "# print(cleaned)\n",
    "print(dmarticle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the article and the hightlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(article):\n",
    "    indx = article.index('@highlight')\n",
    "    story = article[:indx]\n",
    "    highlight = article[indx:].split('@highlight')\n",
    "    highlight = [h.strip() for h in highlight if len(h)>0]\n",
    "    return story,highlight\n",
    "\n",
    "st,hi = split_text(dmarticle)\n",
    "#print(st)\n",
    "#print(hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of the dataset file seems to be usable now. Need to load all of the stories together using these given functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666126fa58c64df4a56893453f64892a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63034a15ee314afc822b29ab5a2c7fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total stories in dataset: 312085\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "def read_all(folder):\n",
    "    dataset = list()\n",
    "\n",
    "    for file in tqdm(listdir(folder)):\n",
    "        filename = folder + '/' + file\n",
    "        article = read_file(filename)\n",
    "        story,highlight = split_text(article)\n",
    "\n",
    "        dataset.append({'story':story, 'highlight':highlight})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "folder = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories\"\n",
    "daily_mail = '/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/dailymail/stories'\n",
    "\n",
    "dataset = read_all(folder)\n",
    "daily_mail_dataset = read_all(daily_mail)\n",
    "dataset.extend(daily_mail_dataset)\n",
    "\n",
    "print(\"total stories in dataset: \"+ str(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zimmerman posts $5,000 bail; he was accused of throwing a bottle at a girlfriend',\n",
       " '\"He hasn\\'t been very lucky with the ladies,\" attorney says of Zimmerman',\n",
       " \"He became a national figure after being charged, then acquitted in Trayvon Martin's death\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[1]['highlight']\n",
    "example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167b0b557f0045dc855532156d529a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "def clean_data(data):\n",
    "    cleaned = list()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in data:\n",
    "        #line = re.split(r\"(CNN)+ --\",line)\n",
    "\n",
    "        dash_indx = line.find(\"--\")\n",
    "        if dash_indx >=0:\n",
    "            line = line[dash_indx+len(\"--\"):]\n",
    "\n",
    "        #line = line.trim()\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lower case\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [w.translate(table) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        cleaned.append(' '.join(line))\n",
    "\t# remove empty strings\n",
    "    cleaned = [c for c in cleaned if len(c) > 0]\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "#dataset[0]['story'] = clean_data(dataset[0]['story'].split('\\n'))\n",
    "#dataset[0]['highlight'] = clean_data(dataset[0]['highlight'])\n",
    "#     #text = re.sub(\"\\n\",\" \",text).lower()\n",
    "# cleaned_dataset = dataset.copy()\n",
    "for i in tqdm(range(len(dataset))):\n",
    "\n",
    "    dataset[i]['story']= clean_data(dataset[i]['story'].split('\\n'))\n",
    "    dataset[i]['highlight'] = clean_data(dataset[i]['highlight'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by',\n",
       " 'travelmail reporter',\n",
       " 'an air traffic controller who allegedly joked to a pilot that he couldnt land is being investigated after the plane was forced to circle a busy airport for an hour and a half',\n",
       " 'as delta flight came in to land at hartsfieldjackson atlanta international airport the controller reportedly joked that the plane couldnt land',\n",
       " 'moments later he said im kidding delta after you land got no one behind you expect to exit right delta clear to land on runway',\n",
       " 'joke gone wrong the delta plane was forced to ascend back to following the alleged joke from an air traffic controller file picture',\n",
       " 'however according to local news organisation atlanta the pilot had already changed course ascending back to after aborting the landing',\n",
       " 'according to the federal aviation administration which is investigating the incident the plane had reached as low as before ascending back to',\n",
       " 'the plane was then forced to circle the airport for an hour and a half while the situation on the ground was clarified and the plane could land safely',\n",
       " 'on the ground the incident took place at hartsfieldjackson atlanta international airport',\n",
       " 'after the air traffic controller told the pilot that he had been kidding the captain responded you sent us around delta is on the go',\n",
       " 'an faa spokesperson told that there was never any danger for the pilot and passengers',\n",
       " 'a spokesperson said the faa is investigating air traffic communications with delta a boeing aircraft on approach to hartsfieldjackson atlanta international airport']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[100000]['story']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "from pickle import dump\n",
    "dump(dataset, open('dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = ['story','highlight']\n",
    "csv_file = \"data.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_pd = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>highlight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['at the start of a big week for the higgs bos...</td>\n",
       "      <td>['usbased scientists say their data points tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['acquitted by a florida jury over the death o...</td>\n",
       "      <td>['zimmerman posts bail he was accused of throw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['zlatan ibrahimovic scored his third goal in ...</td>\n",
       "      <td>['barcelona move three points clear of real ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['nobel laureate norman e borlaug an agricultu...</td>\n",
       "      <td>['borlaug died at the age of from complication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cnnlouisiana gov bobby jindal on monday stoo...</td>\n",
       "      <td>['louisiana gov bobby jindal decried nogo zone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  ['at the start of a big week for the higgs bos...   \n",
       "1  ['acquitted by a florida jury over the death o...   \n",
       "2  ['zlatan ibrahimovic scored his third goal in ...   \n",
       "3  ['nobel laureate norman e borlaug an agricultu...   \n",
       "4  ['cnnlouisiana gov bobby jindal on monday stoo...   \n",
       "\n",
       "                                           highlight  \n",
       "0  ['usbased scientists say their data points tow...  \n",
       "1  ['zimmerman posts bail he was accused of throw...  \n",
       "2  ['barcelona move three points clear of real ma...  \n",
       "3  ['borlaug died at the age of from complication...  \n",
       "4  ['louisiana gov bobby jindal decried nogo zone...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pd.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
