{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using CNN articles as dataset. These articles are stored in multiple files along with their highlights. These highlight can be used to gauge the summary output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try reading the file content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "text = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories/0a0a4c90d59df9e36ffec4ba306b4f20f3ba4acb.story')\n",
    "#text.split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the we need to do some cleaning before we start working on the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(CNN) -- Can a movie actually convince you to support torture? Can a movie really persuade you that \"fracking\" -- a process used to drill for natural gas -- is a danger to the environment? Can a movie truly cause you to view certain minority groups in a negative light?\\n\\nSome scoff at the notion that movies do anything more than entertain. They are wrong. Sure, it\\'s unlikely that one movie alone will change your views on issues of magnitude. But a movie (or TV show) can begin your \"education\" or \"miseducation\" on a topic. And for those already agreeing with the film\\'s thesis, it can further entrench your views.\\n\\nAnyone who doubts the potential influence that movies can have on public opinion need to look no further than two films that are causing an uproar even before they have opened nationwide. They present hot button issues that manage to fire up people from the left and right.\\n\\nThe first, \"Zero Dark Thirty,\" is about the pursuit and killing of Osama bin Laden, which features scenes of torture. The second, \"Promised Land,\" stars Matt Damon and explores how the use of fracking to drill for natural gas can pose health and environmental dangers.\\n\\nCritics of \"Zero Dark Thirty\" fear that audiences will accept as true the film\\'s story line that torture was effective in eliciting information to locate bin Laden. They are rightfully concerned that the film will sway some to become more receptive or even supportive of the idea of torturing prisoners.\\n\\nPeter Bergen: Did torture really net bin Laden?\\n\\nOpposition to the film escalated last week as three senior U.S. senators -- John McCain, Carl Levin and Dianne Feinstein -- sent a letter to the film\\'s distributor, Sony Pictures, characterizing the film\\'s use of torture as \"grossly inaccurate and misleading.\" The senators bluntly informed Sony Pictures that it has \"an obligation to state that the role of torture in the hunt for Osama bin Laden is not based on the facts, but rather part of the film\\'s fictional narrative.\"\\n\\nThe hostility toward \"Promised Land\" shows us that it\\'s not just politicians who complain about movie messages. Big business -- namely, the gas industry -- is aggressively objecting to the allegation in \"Promised Land\" that fracking poses environmental and health risks.\\n\\nHow concerned is the gas industry?\\n\\nIt has set up a rapid response team to counter publicity for the film by using two Washington-based groups that lobby for gas and oil companies: the Independent Petroleum Association of America and Energy in Depth. These groups have scrutinized appearances by the films stars on talk shows, questioned who the financiers of the film are, published parts of the script and mocked the film on social media.\\n\\nEnergy in Depth went as far as to \"fact check\" a recent appearance by the film\\'s co-star and co-writer, John Krasinski, on \"Late Night With David Letterman.\" Within hours of Krasinski\\'s appearance, Energy in Depth posted a blog on its website pointing out what it perceived as factual errors made by Krasinski about fracking.\\n\\nRegardless of whether \"Zero Dark Thirty\" and \"Promised Land\" intended to promote any message, people who watch them will be \"educated\" in some way on torture and fracking -- even if very subtly.\\n\\nThis is the same reason that minority groups continue to object to being represented in a negative light in movies and TV. They understand that accurate representations matter because studies have shown that biases can form based on stereotypes or inaccurate representations. (Being of Italian and Arab descent, I\\'m acutely aware of this issue as my respective heritages have been represented by a parade of mobsters and terrorists.)\\n\\nWhat\\'s Hollywood\\'s role in all of this? The same as it has always been -- to make money.\\n\\nIn fact, there\\'s no doubt that the studios behind these movies are overjoyed at the controversy that has erupted and the resulting free press. Indeed, the response of Sony Pictures to the uproar over \"Zero Dark Thirty\" tells you about what they really hope we will all do: \"We encourage people to see the film before characterizing it.\"\\n\\nSo go ahead, enjoy these films and ones like them that are based on actual events or current hot issues. But while you are watching them, be aware you might be getting more than the price of ticket. You might also be getting a (mis)education.\\n\\nThe opinions expressed in this commentary are solely those of Dean Obeidallah.\\n\\n@highlight\\n\\nDean Obeidallah: A movie or TV show can educate or (mis)educate you\\n\\n@highlight\\n\\nObeidallah: Two new films about hot issues are firing up both the left and right\\n\\n@highlight\\n\\nSenators slammed \"Zero Dark Thirty,\" and energy industry attacked \"Promised Land\"\\n\\n@highlight\\n\\nObeidallah: What does Hollywood want? To make money, of course'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rohankilledar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    # cnn_indx = text.find(\"(CNN)\")\n",
    "    # if cnn_indx >=0:\n",
    "    #     text = text[cnn_indx+len(\"(CNN)\"):]\n",
    "        \n",
    "    #text = re.sub(\"\\n\",\" \",text).lower()\n",
    "\n",
    "    #text.split(\"\\n\")\n",
    "    # cleaned = list()\n",
    "    # table = str.maketrans('','',string.punctuation)\n",
    "\n",
    "    # for line in text:\n",
    "       \n",
    "    #     line = line.split(\" \")\n",
    "\n",
    "    #     line = [w.translate(table) for w in line]\n",
    "        \n",
    "    #     line = [w for w in line if w.isalpha()]\n",
    "    #     cleaned.append(' '.join(line))\n",
    "\n",
    "    # text = [sent for sent in cleaned if len(sent)>0]\n",
    "\n",
    "    return text\n",
    "\n",
    "article = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories/0a0a4c90d59df9e36ffec4ba306b4f20f3ba4acb.story')\n",
    "dmarticle = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/dailymail/stories/0a00a9aebcb754c51534867cf1db2335dcb76884.story')\n",
    "# t = article.split(\"\\n\")\n",
    "# cleaned = list()\n",
    "# table = str.maketrans('','',string.punctuation)\n",
    "# for w in t:\n",
    "#     if len(w)>0:\n",
    "#         w = w.split(\" \")\n",
    "#         w = [word.translate(table) for word in w]\n",
    "#         w = [word for word in w if word.isalpha()]\n",
    "#         cleaned.append(\" \".join(w))\n",
    "# print(cleaned)\n",
    "#print(dmarticle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the article and the hightlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(article):\n",
    "    indx = article.index('@highlight')\n",
    "    story = article[:indx]\n",
    "    highlight = article[indx:].split('@highlight')\n",
    "\n",
    "    highlight = \". \".join([h.strip() for h in highlight if len(h)>0])\n",
    "    return story,highlight\n",
    "\n",
    "#st,hi = split_text(dmarticle)\n",
    "#print(\"story: \"+st)\n",
    "#print(\"highlight: \"+hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st.replace(\"\\n\\n\",\" \").replace(\"\\xa0\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of the dataset file seems to be usable now. Need to load all of the stories together using these given functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d137aba6a64ac0bb2381c3cc87a766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af01879c5f694127bec7090988a1299f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219506 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total stories in dataset: 312085\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "def read_all(folder):\n",
    "    dataset = list()\n",
    "\n",
    "    for file in tqdm(listdir(folder)):\n",
    "        filename = folder + '/' + file\n",
    "        article = read_file(filename)\n",
    "        story,highlight = split_text(article)\n",
    "\n",
    "        dataset.append({'story':story, 'highlight':highlight})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "folder = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories\"\n",
    "daily_mail = '/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/dailymail/stories'\n",
    "\n",
    "dataset = read_all(folder)\n",
    "daily_mail_dataset = read_all(daily_mail)\n",
    "dataset.extend(daily_mail_dataset)\n",
    "\n",
    "print(\"total stories in dataset: \"+ str(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "output_file = open('unprocessed_dataset.pkl','wb')\n",
    "pickle.dump(dataset, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset[53734] # this story contained 100 digit long decimal pointer of pi value and was causing issue while converting the number to its text form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different text preprocessing on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnngeorge zimmerman acquitted by a florida jury over the death of trayvon martin was arrested in florida on suspicion of aggravated assault and domestic violence with a weapon local authorities said\n",
      "the thirtyone year old florida resident was arrested friday by police in lake mary at about ten pm\n",
      "and booked into the john e\n",
      "polk correctional facility according to that facilitys website\n",
      "that facility like its website is run by the seminole county sheriffs office\n",
      "it all came about after zimmerman allegedly threw a wine bottle at a girlfriend his lawyer don west told reporters\n",
      "whatever happened took place several days ago said west\n",
      "and as far as i know they have not been together for some time certainly not since then police first learned about it after coming in contact with the alleged victim at a traffic stop on monday lake mary police spokeswoman bianca gillett said\n",
      "when asked about the delay in making the arrest gillett said the arresting officer tried to reach zimmerman on monday and tuesday but couldnt and was off duty wednesday and thursday\n",
      "it was the officers decision not to pass off the case to another officer gillett said\n",
      "the incident is the latest legal run in for zimmerman since his acquittal in july two thousand and thirteen on a murder charge in the death of martin a seventeen year old african american\n",
      "in fact its his second arrest for alleged domestic violence against a girlfriend though lake mary police spokeswoman bianca gillett said this alleged victim is not the same woman as in 2013 its clear he hasnt been very lucky with the ladies the last few months west said of his client\n",
      "judge bars contact orders weapons surrendered zimmerman appeared saturday morning before judge john galluzo who decided to bar him from contacting the alleged victim or going into volusia county\n",
      "he was also told to surrender any weapons to a relative or third party but not to stop drinking since the judge said there wasnt any allegation of abuse of alcohol in the arrest affidavit appearing in court is not new for zimmerman who became a national figure in two thousand and twelve after spotting martin in his sanford florida neighborhood\n",
      "the two ended up having a confrontation that climaxed with zimmerman fatally shooting the teenager who was unarmed\n",
      "that incident and authorities decision not to immediately charge zimmerman spurred large scale protests\n",
      "in april of that year zimmerman was charged with second degree murder with an affidavit accusing him of profiling martin and ignoring a police dispatchers request that he wait for police\n",
      "after a high profile trial a jury found zimmerman not guilty\n",
      "that made him a free man but did not end his issues with the law\n",
      "no charge after other domestic violence claim about two weeks after the verdict he was pulled over for speeding in northern texas\n",
      "much bigger troubles came in november 2013 when zimmerman was taken into custody at his then girlfriends apoka florida home after the two allegedly had a heated fight\n",
      "he was arrested then on aggravated assault and misdemeanor counts of domestic violence battery and criminal mischief accusations that he denied\n",
      "he posted 9000 bail days later\n",
      "but after the girlfriend asked that the issue be dropped state attorney phil archer announced that prosecutors would not press charges\n",
      "more recently in september 2014 lake mary police said that a man claimed that zimmerman threatened him during a road rage incident\n",
      "i will \n",
      "kill you zimmerman allegedly said according to police\n",
      "do you know who i am he was not arrested and has not been charged\n",
      "west said that his client who posted 5000 bail later saturday doesnt have a full time job implying hes had his struggles since the martin acquittal\n",
      "its been a devastating experience that hes had that hes working through the lawyer said\n",
      "\n",
      "im concerned obviously as we are here again this morning cnns christine sever and chris welch contributed to this report\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "p.number_to_words(1234567)\n",
    "\n",
    "\n",
    "example = dataset[1]['story'].replace(\"\\n\\n\",\" \").replace(\"\\xa0\", \"\").replace('-',' ')\n",
    "#print(example)\n",
    "lines = example.split('. ')\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for line in lines:\n",
    "    token = line.split()\n",
    "    #print(token)\n",
    "    token =  [word.lower() if not word.isnumeric() else p.number_to_words(eval(word)) for word in token]\n",
    "    #print(token)\n",
    "    token = [w.translate(table) for w in token]\n",
    "    #print(token)\n",
    "    # answer = list()\n",
    "    # for word in token:\n",
    "    #     if not word.isnumeric():\n",
    "    #         answer.append(word)\n",
    "    #     else:\n",
    "    #         answer.append(p.number_to_words(int(word)))\n",
    "\n",
    "    answer = [p.number_to_words(int(word)) if isinstance(word,int) else word for word in token ]\n",
    "    #print(answer)\n",
    "    #token = [p.number_to_words(word) for word in token if not word.isalpha()]\n",
    "    #removing the non-characters\n",
    "    sentence = ' '.join(answer).replace('[^A-za-z\\s]+', '')\n",
    "    #normalize\n",
    "    #sentence = sentence.normalize('NFD')\n",
    "    #convert to ASCII from unicode\n",
    "    sentence = sentence.encode('ascii',errors='ignore').decode('utf-8')\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "def clean_data(data):\n",
    "    cleaned = list()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in data:\n",
    "        #line = re.split(r\"(CNN)+ --\",line)\n",
    "\n",
    "        dash_indx = line.find(\"--\")\n",
    "        if dash_indx >=0:\n",
    "            line = line[dash_indx+len(\"--\"):]\n",
    "        \n",
    "        line = line.replace('-',' ')\n",
    "\n",
    "        #line = line.trim()\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lower case and replacing - with space for words like 31-year-old\n",
    "        #line = [word.lower() for word in line]\n",
    "        line = [word.lower() if not word.isdigit() else p.number_to_words(word) for word in line]\n",
    "        #line = [p.number_to_words(int(word)) if isinstance(word,int) else word for word in line ]\n",
    "        #remove all non-characters\n",
    "        #line =[word.replace('[^A-Za-z\\s]+', '') for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [w.translate(table) for w in line]\n",
    "        # remove tokens with numbers in them instead of removing the nisumbers we can convert them into their spelling using inflect library\n",
    "        #line = [word for word in line if word.isalpha()]\n",
    "        # answer = list()\n",
    "        # for word in line:\n",
    "        #     if not isinstance(word,int):\n",
    "        #         answer.append(word)\n",
    "        #     else :\n",
    "        #         answer.append(p.number_to_words(int(word)))\n",
    "\n",
    "        # store as string and removing non-characters\n",
    "        cleaned.append(' '.join(line))\n",
    "\t# remove empty strings\n",
    "    cleaned = [c for c in cleaned if len(c) > 0]\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "#dataset[0]['story'] = clean_data(dataset[0]['story'].split('\\n'))\n",
    "#dataset[0]['highlight'] = clean_data(dataset[0]['highlight'])\n",
    "#     #text = re.sub(\"\\n\",\" \",text).lower()\n",
    "# cleaned_dataset = dataset.copy()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234fcb7f3afa4528abd9e61aaa8f0cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312084 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "\n",
    "    dataset[i]['story']= '. '.join(clean_data(dataset[i]['story'].split('\\n')))#.lstrip(\"[\\'\").rstrip(\"\\']\")\n",
    "    dataset[i]['highlight'] = ''.join(clean_data(dataset[i]['highlight'].split('\\n')))#.lstrip(\"[\\'\").rstrip(\"\\']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acquitted by a florida jury over the death of trayvon martin was arrested in florida on suspicion of aggravated assault and domestic violence with a weapon local authorities said. the thirtyone year old florida resident was arrested friday by police in lake mary at about ten pm and booked into the john e polk correctional facility according to that facilitys website that facility like its website is run by the seminole county sheriffs office. it all came about after zimmerman allegedly threw a wine bottle at a girlfriend his lawyer don west told reporters. whatever happened took place several days ago said west and as far as i know they have not been together for some time certainly not since then. police first learned about it after coming in contact with the alleged victim at a traffic stop on monday lake mary police spokeswoman bianca gillett said. when asked about the delay in making the arrest gillett said the arresting officer tried to reach zimmerman on monday and tuesday but couldnt and was off duty wednesday and thursday it was the officers decision not to pass off the case to another officer gillett said. though lake mary police spokeswoman bianca gillett said this alleged victim is not the same woman as in 2013. its clear he hasnt been very lucky with the ladies the last few months west said of his client. judge bars contact orders weapons surrendered. zimmerman appeared saturday morning before judge john galluzo who decided to bar him from contacting the alleged victim or going into volusia county he was also told to surrender any weapons to a relative or third party but not to stop drinking since the judge said there wasnt any allegation of abuse of alcohol in the arrest affidavit. appearing in court is not new for zimmerman who became a national figure in two thousand and twelve after spotting martin in his sanford florida neighborhood the two ended up having a confrontation that climaxed with zimmerman fatally shooting the teenager who was unarmed. that incident and authorities decision not to immediately charge zimmerman spurred large scale protests in april of that year zimmerman was charged with second degree murder with an affidavit accusing him of profiling martin and ignoring a police dispatchers request that he wait for police. after a high profile trial a jury found zimmerman not guilty. but did not end his issues with the law. no charge after other domestic violence claim. about two weeks after the verdict he was pulled over for speeding in northern texas much bigger troubles came in november 2013 when zimmerman was taken into custody at his then girlfriends apoka florida home after the two allegedly had a heated fight. he was arrested then on aggravated assault and misdemeanor counts of domestic violence battery and criminal mischief accusations that he denied he posted 9000 bail days later. but after the girlfriend asked that the issue be dropped state attorney phil archer announced that prosecutors would not press charges. more recently in september 2014 lake mary police said that a man claimed that zimmerman threatened him during a road rage incident i will  kill you zimmerman allegedly said according to police do you know who i am he was not arrested and has not been charged. who posted 5000 bail later saturday doesnt have a full time job implying hes had his struggles since the martin acquittal. its been a devastating experience that hes had that hes working through the lawyer said  im concerned obviously as we are here again this morning. cnns christine sever and chris welch contributed to this report'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]['story']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = ['story','highlight']\n",
    "csv_file = \"data.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dataset:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_pd = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at the start of a big week for the higgs boson the most soughtafter particle in all of physics scientists in illinois said monday that they had crept closer to proving that the particle exists but had been unable to reach a definitive conclusion. the scientists outlined their final analysis based on more than years of research and trillion particle collisions using the us department of energys fermilab tevatron collider near batavia illinois whose budgetary woes shut it down last year. what is the higgs boson and why is it important. their announcement came two days before researchers at the large hadron collider under the alps are due to unveil their latest results at an eagerly awaited seminar at the cern particle physics laboratory in geneva switzerland. our data strongly point toward the existence of the higgs boson rob roser a spokesman for one of two independent experiments at the tevatron said in a statement but it will take results from the experiments at the large hadron collider in europe to establish a discovery. read more the woman at the edge of physics. finding the higgs boson would help explain the origin of mass one of the open questions in physicists current understanding of the way the universe works. the particle has been so difficult to pin down that the physicist leon lederman reportedly wanted to call his book the goddamn particle but he truncated that epithet to the god particle which may have helped elevate the particles allure in popular culture. more science news from cnn light years. about times the mass of the proton. before the tevatron closed the experiments there sent beams of particles whizzing around a fourmile circumference in opposite directions traveling at a fraction below the speed of light the particles would crash into each other creating conditions similar to those at the dawn of the universe for scientists to observe. but so far neither the results from the us collider experiments nor from the the large hadron collider located feet underneath the border of france and switzerland have enough statistical significance to constitute a discovery. it is easier to look for a friends face in a sports stadium filled with people than to search for a higgslike event among trillions of collisions said luciano ristori a physicist at the us facility. attention now turns to the latest analysis of data from the billion european machine the worlds most powerful particle smasher. we now have more than double the data we had last year sergio bertolucci the director for research and computing at cern said last month that should be enough to see whether the trends we were seeing in the data are still there or whether theyve gone away its a very exciting time. scientists getting clearer picture of god particle'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_pd['highlight'][0].lstrip(\"[\\'\").rstrip(\"\\']\")\n",
    "dataset_pd['story'][0].lstrip(\"[\\'\").rstrip(\"\\']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "output_file = open('dataset.pkl','wb')\n",
    "pickle.dump(dataset_pd, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_pd['highlight'] = dataset_pd['highlight'].apply(lambda x:  'sostok ' + x.lstrip(\"[\\'\").rstrip(\"\\']\") + ' eostok')\n",
    "#dataset_pd['story'] = dataset_pd['story'].apply(lambda x: x.lstrip(\"[\\'\").rstrip(\"\\']\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_pd.drop('hightlight1', axis=1, inplace=True)\n",
    "dataset_pd['word_count_text'] = dataset_pd['story'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 percentile value is 1\n",
      " 10 percentile value is 293\n",
      " 20 percentile value is 379\n",
      " 30 percentile value is 451\n",
      " 40 percentile value is 521\n",
      " 50 percentile value is 592\n",
      " 60 percentile value is 672\n",
      " 70 percentile value is 766\n",
      " 80 percentile value is 891\n",
      " 90 percentile value is 1096\n",
      "100 percentile value is  2094\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(0,100,10) :\n",
    "    var =dataset_pd[\"word_count_text\"]. values\n",
    "    var = np.sort(var,axis = None)\n",
    "    print (\" {} percentile value is {}\".format (i,var[int(len(var)*(float(i)/100))]))\n",
    "print (\"100 percentile value is \",var[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-002ca5bc5857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdataset_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_count_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} percentile value is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"100 percentile value is \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range (90,100) :\n",
    "    var =dataset_pd[\"word_count_text\"].values\n",
    "    var = np.sort(var, axis = None)\n",
    "    print(\"{} percentile value is {}\".format(i, var[int (len(var)*(float (i)/100))]))\n",
    "print (\"100 percentile value is \", var[-1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
