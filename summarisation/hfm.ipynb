{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from pprint import pprint\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from os import listdir\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_downloaded_files = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/Natural Language Processing/glove.6B.50d.txt\"\n",
    "filename = \"glove.6B.50d.txt\"\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "sos = 'sos'\n",
    "eos = 'eos'\n",
    "\n",
    "embedding_dim = hidden_size = 50\n",
    "data_size = 10000\n",
    "MAX_LENGTH = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_file = datapath(path_of_downloaded_files)\n",
    "# word2vec_glove_file = get_tmpfile(filename)\n",
    "# glove2word2vec(glove_file, word2vec_glove_file)\n",
    "# word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "# print('loaded %s word vectors from %s.' % (len(word_vectors.key_to_index),filename ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/Users/rohankilledar/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n",
      "Reusing dataset cnn_dailymail (/Users/rohankilledar/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n",
      "Reusing dataset cnn_dailymail (/Users/rohankilledar/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n",
      "Reusing dataset cnn_dailymail (/Users/rohankilledar/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n",
      "100%|██████████| 3/3 [00:00<00:00, 41.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287113\n",
      "11490\n",
      "13368\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('ccdv/cnn_dailymail','3.0.0',split = 'train')  \n",
    "test_dataset = load_dataset('ccdv/cnn_dailymail','3.0.0',split = 'test')  \n",
    "validation_dataset = load_dataset('ccdv/cnn_dailymail','3.0.0',split = 'validation')  \n",
    "\n",
    "entire_dataset = load_dataset('ccdv/cnn_dailymail', '3.0.0')\n",
    "\n",
    "print(train_dataset.__len__())\n",
    "print(test_dataset.__len__())\n",
    "print(validation_dataset.__len__())\n",
    "print(entire_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "embedding_glove = GloVe(name='6B', dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train' : train_dataset,\n",
    "    'test' : test_dataset,\n",
    "    'validation' : validation_dataset\n",
    "}\n",
    "\n",
    "with open(\"hf_dataset.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(dataset, save_path)\n",
    "\n",
    "# with open('hf_dataset.pkl','rb') as ff:\n",
    "#     hfd = pickle.load(ff)\n",
    "\n",
    "# train_ds = hfd['train']\n",
    "# train_df = train_ds.data.to_pandas()\n",
    "# test_ds = hfd['test']\n",
    "# test_df = test_ds.data.to_pandas()\n",
    "# valid_ds = hfd['validation']\n",
    "# valid_df = valid_ds.data.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_dataset.data.to_pandas()\n",
    "# train_df = pd.DataFrame.from_dict(train_dataset)\n",
    "train_df = train_dataset.data.to_pandas()\n",
    "test_df = test_dataset.data.to_pandas()\n",
    "valid_df = validation_dataset.data.to_pandas()\n",
    "dataset_list = [train_df,test_df,valid_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of t...</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world cham...</td>\n",
       "      <td>Usain Bolt wins third gold of world championsh...</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas City, Missouri (CNN) -- The General Ser...</td>\n",
       "      <td>The employee in agency's Kansas City office is...</td>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- A medical doctor in Vanco...</td>\n",
       "      <td>NEW: A Canadian doctor says she was part of a ...</td>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN) -- Police arrested another teen Thursday...</td>\n",
       "      <td>Another arrest made in gang rape outside Calif...</td>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  It's official: U.S. President Barack Obama wan...   \n",
       "1  (CNN) -- Usain Bolt rounded off the world cham...   \n",
       "2  Kansas City, Missouri (CNN) -- The General Ser...   \n",
       "3  Los Angeles (CNN) -- A medical doctor in Vanco...   \n",
       "4  (CNN) -- Police arrested another teen Thursday...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Syrian official: Obama climbed to the top of t...   \n",
       "1  Usain Bolt wins third gold of world championsh...   \n",
       "2  The employee in agency's Kansas City office is...   \n",
       "3  NEW: A Canadian doctor says she was part of a ...   \n",
       "4  Another arrest made in gang rape outside Calif...   \n",
       "\n",
       "                                         id  \n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef  \n",
       "2  00027e965c8264c35cc1bc55556db388da82b07f  \n",
       "3  0002c17436637c4fe1837c935c04de47adb18e9a  \n",
       "4  0003ad6ef0c37534f80b55b4235108024b407f0b  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_reduced = train_dataset[:2000]\n",
    "# train_reduced = pd.DataFrame.from_dict(train_reduced)\n",
    "# train_reduced['article'] = train_reduced['article'].apply(lambda x: normalizeString(x))\n",
    "# train_reduced['highlights'] = train_reduced['highlights'].apply(lambda x: normalizeString(x))\n",
    "# train_reduced.drop('id', axis=1, inplace=True)\n",
    "# train_reduced.head()\n",
    "\n",
    "# train_reduced = train_reduced[train_reduced['article'].str.split().str.len().lt(mean_article_len)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase): \n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase) \n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)  \n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)  \n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)  \n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)  \n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)  \n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)  \n",
    "    phrase = re.sub(r'ain\\'t', \"is not\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    un = '(CNN)'\n",
    "    dash_indx = s.find(un)\n",
    "    if dash_indx>-1: #and dash_indx<=20:\n",
    "        s = s[dash_indx+len(un):]\n",
    "    \n",
    "    s = s.lower().strip()\n",
    "    s=decontracted(s)\n",
    "\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r'\\.', r' . ', s)\n",
    "    \n",
    "\n",
    "    # s = ' '.join([word for word in s.split(' ') if word not in stop_words and word in vocab.word2index.keys()])\n",
    "  \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def drop_data_id(dataset_list):\n",
    "    for data in dataset_list:\n",
    "        data.drop('id', axis=1, inplace=True)\n",
    "\n",
    "drop_data_id(dataset_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {'sos': 0 , 'eos': 1}\n",
    "        self.word2count = {'sos': 1, 'eos': 1}\n",
    "        self.index2word = {0: \"sos\", 1: \"eos\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in regTokenize(sentence):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def addFromPretrained(self,emb):\n",
    "        for i in range(len(embedding_glove)):\n",
    "            word = embedding_glove.itos[i]\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.word2count[word] = 1\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words +=1\n",
    "            \n",
    "\n",
    "# vocab = Lang('vocab')\n",
    "# vocab.addFromPretrained(embedding_glove)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['article'] = train_df['article'].apply(lambda x: normalizeString(x))\n",
    "train_df['highlights'] = train_df['highlights'].apply(lambda x: normalizeString(x))\n",
    "# test_df['article'] = test_df['article'].apply(lambda x: normalizeString(x))\n",
    "# test_df['highlights'] = test_df['highlights'].apply(lambda x: normalizeString(x))\n",
    "# valid_df['article'] = valid_df['article'].apply(lambda x: normalizeString(x))\n",
    "# valid_df['highlights'] = valid_df['highlights'].apply(lambda x: normalizeString(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean word count length of text article is 727\n",
      "The mean word count length of summary/highlight is 52\n",
      "The max word count length of text article is 2785\n",
      "The max word count length of summary/highlight is 1278\n"
     ]
    }
   ],
   "source": [
    "train_df['word_count_text'] = train_df['article'].apply(lambda x: len(str(x).split()))\n",
    "train_df['highlight_count'] = train_df['highlights'].apply(lambda x: len(str(x).split()))\n",
    "from math import floor\n",
    "\n",
    "mean_article_len = floor(train_df['word_count_text'].mean())\n",
    "mean_hightlight_len = floor(train_df['highlight_count'].mean())\n",
    "\n",
    "max_article_len = floor(train_df['word_count_text'].max())\n",
    "max_hightlight_len = floor(train_df['highlight_count'].max())\n",
    "\n",
    "\n",
    "\n",
    "print(\"The mean word count length of text article is \" + str(mean_article_len))\n",
    "print(\"The mean word count length of summary/highlight is \" + str(mean_hightlight_len))\n",
    "\n",
    "\n",
    "print(\"The max word count length of text article is \" + str(max_article_len))\n",
    "print(\"The max word count length of summary/highlight is \" + str(max_hightlight_len))\n",
    "\n",
    "train_df.drop('word_count_text', axis=1, inplace=True)\n",
    "train_df.drop('highlight_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_train_df.DataFrame\",\"wb\") as save_path:\n",
    "    pickle.dump(train_df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using this tokenizer as its the fastest way to tokenize sentences.\n",
    "WORD = re.compile(r'\\w+')\n",
    "def regTokenize(text):\n",
    "    words = WORD.findall(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Lang(object):\n",
    "#     def __init__(self,vocab_file) -> None:\n",
    "#         self.word2index = {}\n",
    "#         self.index2word = {}\n",
    "\n",
    "#         index = 0\n",
    "#         for word in [pad,unk,sos, eos]:\n",
    "#             self.word2index[word] = index\n",
    "#             self.index2word[index] = word\n",
    "#             index +=1\n",
    "\n",
    "#         with open(vocab_file, 'r') as f:\n",
    "#             for line in f:\n",
    "#                 try:\n",
    "#                     word = line.split()[0]\n",
    "#                     self.word2index[word] = index\n",
    "#                     self.index2word[index] = word\n",
    "#                     index +=1\n",
    "\n",
    "#                 except ValueError as e:\n",
    "#                     print(\"Error in line {}: {}\".format(token_counter - 4, e))\n",
    "\n",
    "#     def word2index(self,word: str) -> int:\n",
    "#         if word == eos:\n",
    "#             return self.word2index['.']\n",
    "#         elif word not in self.word2index:\n",
    "#             return self.word2index[]\n",
    "\n",
    "# new_vocab = Lang(path_of_downloaded_files)\n",
    "# print(len(new_vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Lang:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.words = []\n",
    "#         self.word2index = {}\n",
    "#         self.word2count = {}\n",
    "#         self.index2word = {}\n",
    "#         self.n_words = 0  # Count SOS and EOS\n",
    "#         self.glove = {}\n",
    "#         self.embedding_dim = word_vectors.get_vector('office').shape[0]\n",
    "\n",
    "#     def addSentence(self, sentence):\n",
    "#         for word in regTokenize(sentence):\n",
    "#             self.addWord(word)\n",
    "\n",
    "#     def addWord(self, word):\n",
    "#         if word not in self.words:\n",
    "#             self.words.append(word)\n",
    "#             self.word2index[word] = self.n_words\n",
    "#             self.word2count[word] = 1\n",
    "#             self.index2word[self.n_words] = word\n",
    "#             self.n_words += 1\n",
    "#             if word not in self.glove:\n",
    "#                 self.glove[word] = np.random.normal(scale=0.6 , size= (self.embedding_dim,))\n",
    "#         else:\n",
    "#             self.word2count[word] += 1\n",
    "\n",
    "#     def addPretrained(self,path_of_downloaded_files):\n",
    "#         with open(path_of_downloaded_files) as f:\n",
    "#             for indx,l in tqdm(enumerate(f)):\n",
    "#                 line = l.split()\n",
    "#                 word = line[0]\n",
    "#                 if word == sos:\n",
    "#                     first_word = self.words[0]\n",
    "#                     self.words.append(first_word)\n",
    "#                     self.words[0] = sos\n",
    "#                     self.word2index[first_word] = indx\n",
    "#                     self.word2index[sos] = 0\n",
    "#                     self.index2word[indx] = first_word\n",
    "#                     self.index2word[0] = sos\n",
    "#                     self.glove[sos] = word_vectors[indx]\n",
    "#                     #self.glove[first_word] = word_vectors[0]\n",
    "#                     self.word2count[sos] = 1\n",
    "#                     self.n_words += 1\n",
    "\n",
    "#                 elif word == eos:\n",
    "#                     sec_word = self.words[1]\n",
    "#                     self.words.append(sec_word)\n",
    "#                     self.words[1] = eos\n",
    "#                     self.index2word[indx] = sec_word\n",
    "#                     self.index2word[1] = eos\n",
    "#                     self.word2index[sec_word] = indx\n",
    "#                     self.word2index[eos] = 1\n",
    "#                     self.glove[eos] = word_vectors[indx]\n",
    "#                     #self.glove[sec_word] = word_vectors[1]\n",
    "#                     self.word2count[eos] = 1\n",
    "#                     self.n_words += 1\n",
    "#                 else:\n",
    "#                     self.words.append(word)\n",
    "#                     self.word2count[word] = 1\n",
    "#                     self.word2index[word] = indx\n",
    "#                     self.index2word[indx]=word\n",
    "#                     self.glove[word] = word_vectors[indx]\n",
    "#                     self.n_words += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7874defa7df34cb1b63378d981bdc59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted Words:\n",
      "vocab 658217\n"
     ]
    }
   ],
   "source": [
    "vocab = Lang('vocab')\n",
    "vocab.addFromPretrained(path_of_downloaded_files)\n",
    "def prepareData(vocab):\n",
    "    for _ ,row in tqdm(train_df.iterrows()):\n",
    "        vocab.addSentence(row['article'])\n",
    "        vocab.addSentence(row['highlights'])\n",
    "    print(\"counted Words:\")\n",
    "    print(vocab.name, vocab.n_words)\n",
    "    \n",
    "prepareData(vocab)\n",
    "\n",
    "with open(\"vocab.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(vocab, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(vocab, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = train_df.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pair(data, max_len):\n",
    "    return len(data[0].split(' ')) < max_len\n",
    "\n",
    "def filter_pairs(pairs, max_len):\n",
    "    return [pair for pair in pairs if filter_pair(pair,max_len)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = filter_pairs(pairs, mean_article_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentences(lang, sentence):\n",
    "    return [lang.word2index[word] for word in regTokenize(sentence)]\n",
    "\n",
    "def tensorFromSentences(lang, sentence):\n",
    "    indexes = indexesFromSentences(lang,sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype = torch.long).view(-1,1)\n",
    "\n",
    "def tensorFromPair(pair):\n",
    "    input_tensor = tensorFromSentences(vocab, pair[0])\n",
    "    target_tensor = tensorFromSentences(vocab, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words processed: 658217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_weights(unique_word_corpus, tens=True):\n",
    "    matrix_len = len(unique_word_corpus)\n",
    "    \n",
    "    \n",
    "    weight_matrix  = np.zeros((matrix_len, embedding_dim))\n",
    "   \n",
    "    words_found = 0\n",
    "    \n",
    "\n",
    "    for indx, word in enumerate(unique_word_corpus):\n",
    "        # try:\n",
    "            # if word is not in the embedding this function assign zero value to that vector\n",
    "        weight_matrix[indx] = embedding_glove.get_vecs_by_tokens(word)\n",
    "        words_found +=1\n",
    "\n",
    "        # except KeyError:\n",
    "\n",
    "        #     weight_matrix[indx] = np.random.normal(scale=0.6 , size= (embedding_dim,))\n",
    "        #     random_weights +=1\n",
    "    print(f'total words processed: {words_found}')\n",
    "    # print(f'embedding initialized to random value for {random_weights} no. of words')\n",
    "    if tens:\n",
    "        return torch.from_numpy(weight_matrix) \n",
    "    else:\n",
    "        return weight_matrix\n",
    "\n",
    "weight_matrix= generate_weights(vocab.word2index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix = weight_matrix.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "       \n",
    "\n",
    "       # self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size,hidden_size)\n",
    "        self.embedding = self.embedding.from_pretrained(weight_matrix, freeze = True)\n",
    "        \n",
    "        ## trying gru\n",
    "        # self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = hidden_size, hidden_size = hidden_size) #, num_layers = 1, bidirectional = True, batch_first = True)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = embedded\n",
    "        \n",
    "        # output, hidden = self.gru(output, hidden)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        #in case of LSTM we need h0 and c0 hence init this as a tuple (h0,c0) and passed as hidden to lstm and in case of gru its just h0\n",
    "        return (torch.zeros(1, 1, self.hidden_size, dtype=torch.float, device=device), torch.zeros(1,1,self.hidden_size,dtype = torch.float, device= device))\n",
    "        # return torch.zeros(1,1,self.hidden_size, device=device)\n",
    "\n",
    "# %%\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings= output_size,embedding_dim= hidden_size)\n",
    "        # self.gru = nn.GRU(hidden_size,hidden_size)\n",
    "        self.embedding = self.embedding.from_pretrained(weight_matrix, freeze = True)\n",
    "        self.lstm = nn.LSTM(input_size= hidden_size, hidden_size= hidden_size) #, num_layers = 1, bidirectional = False, batch_first = True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim= 1)\n",
    "        # self.softmax = nn.Softmax(dim = 1)\n",
    "       # self.fc = nn.Linear(in_features= hidden_size , out_features=vocab.n_words)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = torch.tanh(embedded)\n",
    "        # output, hidden = self.gru(output, hidden)\n",
    "        output, hidden = self.lstm(output.float(), hidden)\n",
    "        #output = self.softmax(self.out(output[0]))\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        # output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHiddden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, dtype=torch.float, device=device), torch.zeros(1,1,self.hidden_size,dtype = torch.float, device= device))\n",
    "\n",
    "\n",
    "# %%\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_article_len):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.embedding.from_pretrained(weight_matrix)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "       \n",
    "    \n",
    "        AttnDecoderRNN.embedded = embedded\n",
    "        \n",
    "        AttnDecoderRNN.hidden = hidden\n",
    "        AttnDecoderRNN.encoder_outputs = encoder_outputs\n",
    "\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0].view(1,-1)), 1)), dim=1)\n",
    "        # print(attn_weights.unsqueeze(0).shape, encoder_outputs.unsqueeze(0).shape)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "                                 \n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "       return (torch.zeros(1, 1, self.hidden_size, dtype=torch.int64, device=device), torch.zeros(1,1,self.hidden_size,dtype = torch.int64, device= device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, attn = True, max_length=max_article_len):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_article_len, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if attn :\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden= decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                #tar_tens = weight_matrix[target_tensor[di].item()].view(-1).float()\n",
    "                # target_tensor -> tensor(4,dtype=long)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            if attn :\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden= decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "            \n",
    "            # sm = nn.Softmax(decoder_output)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            # topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            # tar -> tensor((4)) dtype = long/int64\n",
    "            #dec -> size(1,vocab_size) dtype = float\n",
    "            # tar_tens = weight_matrix[target_tensor[di].item()].view(-1).float()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            # sys.stdout.write(\"\\rtarget: %s\" % vocab.index2word[target_tensor[di].item()])\n",
    "            sys.stdout.write(\"\\rdecoded: %s\" % vocab.index2word[topi.item()])\n",
    "            sys.stdout.flush()\n",
    "            train.dout = decoder_output\n",
    "            # print(f'target output: {summary_vocab.index2word[target_tensor[di].item()]}')\n",
    "            # print(f'decoded output: {vocab.index2word[decoder_output.data.topk(1)[1].item()]} ')\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "#try different learning rate\n",
    "def trainIters(encoder, decoder, n_iters, attn=False, print_every=1000, plot_every=100, learning_rate=0.1):\n",
    "    start = time.time()\n",
    "    if attn:\n",
    "        print(\"training with attention.\")\n",
    "    \n",
    "\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    print('encoder optimizer init')\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    print('decoder optimizer init')\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    print('choosing training pairs:' + str(n_iters))\n",
    "    training_pairs = [tensorFromPair(random.choice(pairs))\n",
    "                      for _ in range(n_iters)]\n",
    "    \n",
    "    print(f'filtering the pairs with max article size of {mean_article_len}')\n",
    "    \n",
    "    \n",
    "    print('init criterion')\n",
    "    criterion = nn.NLLLoss()\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    print('starting iterations')\n",
    "    \n",
    "    for iter in tqdm(range(1, n_iters + 1)):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, attn)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "def evaluate(encoder, decoder, sentence ,max_length=max_article_len, attn=True): # please check what should be max_length\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentences(vocab, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_article_len, encoder.hidden_size, device=device)\n",
    "        print('evaluation init')\n",
    "        for ei in range(input_length):\n",
    "            \n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(99):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        # print(decoder_attention,decoder_attention.shape)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        if topi.item() == EOS_token:\n",
    "            decoded_words.append(eos)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(vocab.index2word[topi.item()])\n",
    "\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "     #   print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with attention.\n",
      "encoder optimizer init\n",
      "decoder optimizer init\n",
      "choosing training pairs:30000\n",
      "filtering the pairs with max article size of 727\n",
      "init criterion\n",
      "starting iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c0c05efeef48db8625a0a12db02f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded: the8m 19s (- 991m 24s) (250 0%) 9.4162\n",
      "decoded: has16m 45s (- 988m 48s) (500 1%) 8.1918\n",
      "decoded: eos24m 56s (- 972m 32s) (750 2%) 8.2894\n",
      "decoded: eos33m 8s (- 960m 59s) (1000 3%) 8.1810\n",
      "decoded: in41m 0s (- 943m 7s) (1250 4%) 7.3423\n",
      "decoded: and49m 29s (- 940m 26s) (1500 5%) 7.7972\n",
      "decoded: eos57m 39s (- 930m 53s) (1750 5%) 7.8183\n",
      "decoded: the66m 46s (- 934m 51s) (2000 6%) 8.0862\n",
      "decoded: with75m 7s (- 926m 28s) (2250 7%) 7.2223\n",
      "decoded: the83m 49s (- 922m 1s) (2500 8%) 7.5007\n",
      "decoded: eos92m 14s (- 914m 3s) (2750 9%) 7.5574\n",
      "decoded: in99m 34s (- 896m 12s) (3000 10%) 6.8960\n",
      "decoded: eos108m 17s (- 891m 18s) (3250 10%) 7.5619\n",
      "decoded: his117m 15s (- 887m 48s) (3500 11%) 7.7724\n",
      "decoded: eos125m 33s (- 878m 54s) (3750 12%) 7.5668\n",
      "decoded: they133m 45s (- 869m 23s) (4000 13%) 7.6948\n",
      "decoded: eos142m 38s (- 864m 16s) (4250 14%) 7.8455\n",
      "decoded: is151m 11s (- 856m 47s) (4500 15%) 7.5405\n",
      "decoded: to159m 19s (- 846m 57s) (4750 15%) 7.4208\n",
      "decoded: a167m 57s (- 839m 48s) (5000 16%) 7.6170\n",
      "decoded: to176m 39s (- 832m 49s) (5250 17%) 7.8589\n",
      "decoded: eos185m 4s (- 824m 26s) (5500 18%) 7.6533\n",
      "decoded: he193m 52s (- 817m 38s) (5750 19%) 7.6371\n",
      "decoded: a202m 21s (- 809m 26s) (6000 20%) 7.6605\n",
      "decoded: eos211m 3s (- 801m 59s) (6250 20%) 7.3830\n",
      "decoded: a219m 31s (- 793m 41s) (6500 21%) 7.6520\n",
      "decoded: eos227m 32s (- 783m 46s) (6750 22%) 7.1355\n",
      "decoded: in235m 53s (- 775m 3s) (7000 23%) 7.5783\n",
      "decoded: and244m 21s (- 766m 46s) (7250 24%) 7.8077\n",
      "decoded: eos253m 10s (- 759m 30s) (7500 25%) 7.6513\n",
      "decoded: eos261m 18s (- 750m 13s) (7750 25%) 7.4267\n",
      "decoded: the269m 54s (- 742m 14s) (8000 26%) 7.5372\n",
      "decoded: the278m 11s (- 733m 25s) (8250 27%) 7.3868\n",
      "decoded: on286m 42s (- 725m 12s) (8500 28%) 7.5246\n",
      "decoded: in295m 5s (- 716m 38s) (8750 29%) 7.4503\n",
      "decoded: eos303m 28s (- 708m 7s) (9000 30%) 7.2812\n",
      "decoded: the312m 4s (- 700m 3s) (9250 30%) 7.4801\n",
      "decoded: a320m 21s (- 691m 17s) (9500 31%) 7.3979\n",
      "decoded: new328m 54s (- 683m 6s) (9750 32%) 7.4762\n",
      "decoded: eos336m 32s (- 673m 4s) (10000 33%) 7.0400\n",
      "decoded: the345m 2s (- 664m 49s) (10250 34%) 7.5300\n",
      "decoded: in353m 28s (- 656m 26s) (10500 35%) 7.2943\n",
      "decoded: of361m 55s (- 648m 5s) (10750 35%) 7.4800\n",
      "decoded: she370m 12s (- 639m 26s) (11000 36%) 7.2406\n",
      "decoded: a378m 57s (- 631m 35s) (11250 37%) 7.4587\n",
      "decoded: the387m 38s (- 623m 35s) (11500 38%) 7.5396\n",
      "decoded: is395m 44s (- 614m 39s) (11750 39%) 7.1453\n",
      "decoded: and404m 19s (- 606m 29s) (12000 40%) 7.5155\n",
      "decoded: is412m 29s (- 597m 41s) (12250 40%) 7.0233\n",
      "decoded: eos420m 58s (- 589m 21s) (12500 41%) 7.4069\n",
      "decoded: the429m 32s (- 581m 8s) (12750 42%) 7.3556\n",
      "decoded: a437m 42s (- 572m 22s) (13000 43%) 7.2642\n",
      "decoded: eos446m 1s (- 563m 50s) (13250 44%) 7.3811\n",
      "decoded: to454m 19s (- 555m 17s) (13500 45%) 7.4803\n",
      "decoded: eos463m 1s (- 547m 12s) (13750 45%) 7.4061\n",
      "decoded: she472m 49s (- 540m 22s) (14000 46%) 7.3781\n",
      "decoded: the482m 3s (- 532m 48s) (14250 47%) 7.3065\n",
      "decoded: the490m 46s (- 524m 37s) (14500 48%) 7.5201\n",
      "decoded: a498m 56s (- 515m 51s) (14750 49%) 7.3431\n",
      "decoded: is508m 34s (- 508m 34s) (15000 50%) 7.9491\n",
      "decoded: of516m 46s (- 499m 49s) (15250 50%) 7.3278\n",
      "decoded: to524m 51s (- 491m 0s) (15500 51%) 6.9818\n",
      "decoded: in532m 29s (- 481m 46s) (15750 52%) 6.9517\n",
      "decoded: of541m 18s (- 473m 38s) (16000 53%) 7.6132\n",
      "decoded: and550m 7s (- 465m 29s) (16250 54%) 7.4413\n",
      "decoded: the559m 15s (- 457m 34s) (16500 55%) 7.7510\n",
      "decoded: and567m 13s (- 448m 41s) (16750 55%) 7.1024\n",
      "decoded: is575m 0s (- 439m 42s) (17000 56%) 6.8895\n",
      "decoded: for583m 23s (- 431m 11s) (17250 57%) 7.2206\n",
      "decoded: him591m 21s (- 422m 23s) (17500 58%) 7.0709\n",
      "decoded: to600m 17s (- 414m 17s) (17750 59%) 7.3424\n",
      "decoded: is608m 55s (- 405m 56s) (18000 60%) 7.0404\n",
      "decoded: in616m 40s (- 397m 2s) (18250 60%) 7.1242\n",
      "decoded: and625m 35s (- 388m 52s) (18500 61%) 7.7040\n",
      "decoded: is633m 56s (- 380m 22s) (18750 62%) 7.2784\n",
      "decoded: eos641m 57s (- 371m 39s) (19000 63%) 7.2782\n",
      "decoded: eos649m 38s (- 362m 47s) (19250 64%) 6.9015\n",
      "decoded: a657m 24s (- 353m 59s) (19500 65%) 6.9334\n",
      "decoded: eos665m 45s (- 345m 31s) (19750 65%) 7.4301\n",
      "decoded: the674m 1s (- 337m 0s) (20000 66%) 6.9077\n",
      "decoded: to682m 28s (- 328m 35s) (20250 67%) 7.4258\n",
      "decoded: the690m 43s (- 320m 5s) (20500 68%) 7.1628\n",
      "decoded: of699m 14s (- 311m 42s) (20750 69%) 7.3694\n",
      "decoded: eos707m 31s (- 303m 13s) (21000 70%) 7.2035\n",
      "decoded: the716m 4s (- 294m 51s) (21250 70%) 7.1928\n",
      "decoded: in724m 41s (- 286m 30s) (21500 71%) 7.5211\n",
      "decoded: in732m 40s (- 277m 54s) (21750 72%) 6.9660\n",
      "decoded: to741m 12s (- 269m 31s) (22000 73%) 7.4203\n",
      "decoded: to749m 29s (- 261m 3s) (22250 74%) 7.2920\n",
      "decoded: in757m 18s (- 252m 26s) (22500 75%) 7.2061\n",
      "decoded: is765m 27s (- 243m 56s) (22750 75%) 7.0518\n",
      "decoded: is774m 13s (- 235m 38s) (23000 76%) 7.2335\n",
      "decoded: the783m 7s (- 227m 21s) (23250 77%) 7.4922\n",
      "decoded: her791m 33s (- 218m 56s) (23500 78%) 7.4701\n",
      "decoded: eos800m 12s (- 210m 34s) (23750 79%) 7.4190\n",
      "decoded: a808m 49s (- 202m 12s) (24000 80%) 7.2198\n",
      "decoded: in816m 56s (- 193m 42s) (24250 80%) 7.3455\n",
      "decoded: the825m 25s (- 185m 18s) (24500 81%) 7.2693\n",
      "decoded: eos833m 58s (- 176m 54s) (24750 82%) 7.4937\n",
      "decoded: eos842m 46s (- 168m 33s) (25000 83%) 7.5514\n",
      "decoded: a851m 43s (- 160m 13s) (25250 84%) 7.6249\n",
      "decoded: and860m 12s (- 151m 48s) (25500 85%) 7.2529\n",
      "decoded: the868m 48s (- 143m 23s) (25750 85%) 6.9456\n",
      "decoded: is878m 20s (- 135m 7s) (26000 86%) 7.3235\n",
      "decoded: the887m 59s (- 126m 51s) (26250 87%) 7.3866\n",
      "decoded: eos896m 53s (- 118m 27s) (26500 88%) 7.0938\n",
      "decoded: is905m 1s (- 109m 57s) (26750 89%) 6.8624\n",
      "decoded: the914m 37s (- 101m 37s) (27000 90%) 7.4036\n",
      "decoded: in923m 41s (- 93m 12s) (27250 90%) 7.3194\n",
      "decoded: in933m 25s (- 84m 51s) (27500 91%) 7.5595\n",
      "decoded: the943m 15s (- 76m 28s) (27750 92%) 7.3440\n",
      "decoded: to952m 59s (- 68m 4s) (28000 93%) 7.6440\n",
      "decoded: a961m 56s (- 59m 35s) (28250 94%) 7.3712\n",
      "decoded: in970m 39s (- 51m 5s) (28500 95%) 7.3600\n",
      "decoded: in979m 55s (- 42m 36s) (28750 95%) 7.4139\n",
      "decoded: to988m 25s (- 34m 5s) (29000 96%) 7.3253\n",
      "decoded: eos998m 30s (- 25m 36s) (29250 97%) 7.6373\n",
      "decoded: the1007m 3s (- 17m 4s) (29500 98%) 7.0825\n",
      "decoded: the1015m 14s (- 8m 31s) (29750 99%) 6.8880\n",
      "decoded: he1024m 44s (- 0m 0s) (30000 100%) 7.0951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "hidden_size = 50\n",
    "voc_size = len(vocab.word2index)\n",
    "hidden_dim = 50\n",
    "# max_summary_size = 60\n",
    "encoder1 = EncoderRNN(vocab.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab.n_words).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, vocab.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "\n",
    "# %%\n",
    "# trainIters(encoder1, decoder1, 300, print_every=10)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1,30000,True, print_every=250)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= remix of justin bieber is u smile has more than  .  million plays on soundcloud  . com  .  producer nick pittsinger says he slowed down the song percent  .  mtv disagrees saying the song is actually an untitled song from the photon wave orchestra  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= influential british rock band the stone roses to reform after year hiatus  .  music writer says group will want gigs to improve the stone roses legacy  .  paul stokes says older groups allow fans to experience better quality music  .  but he says reformed acts are in danger of soaking up much of the live market  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= anderlecht tweeted a snap of anthony vanden borre reading the daily mail  .  the anderlecht star scored two in a three goal revival at the emirates  .  the visitors equalised in the final minute through aleksandar mitrovic  .  chancel mbemba also pictured reading a copy of wednesday is daily mail  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= both locations are in tripoli  .  escaped detainees provided testimony  .  amnesty says killing prisoners is a war crime  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= winning numbers on wednesday were and powerball  .  biggest powerball jackpot of  .  million was won by year old florida widow in may  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= doctors injected botox into the vocal cords of asthma patients  .  this partially paralysed the muscles causing them to relax  .  this helped them breathe and the effect lasted up to three months  .  the patients improved but some found their voices became softer  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= orcas had been confined to a space of about feet by feet  .  an inukjuak town manager says shifting wind patterns overnight allowed the ice to break  .  the incident is reminiscent of a rescue of gray whales that were trapped near alaska  .  the story made national news and was the inspiration for the film big miracle \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= ed miliband said he is never taken illegal drugs but has read about effects  .  is opposed to decriminalisation of drugs as it sends wouldangerous message said government should look at ways to discourage people taking drugs  .  added labour is finalising plans to promise a cut in university tuition fees  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= aircraft would take minutes to fly from new york to los angeles  .  model launched from vandenberg air force base on central california coast  .  u  . s  .  agency reported successful launch but lost contact later  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n",
      "= hard working grandfather jerzy dubiniec was kicked so hard he had shoe marks all over his clothes and chest  .  gavin mills was high on cocaine  .  and alcohol when he carried out the random attack on baker mr dubiniec  .  who was on his way home from work  . \n",
      "evaluation init\n",
      "< the of the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the to the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dout.data.topk(1)\n",
    "vocab.index2word[9]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
