{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from os import listdir\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_file_name = 'unprocessed_file.pkl'\n",
    "cleaned_file_name ='cleaned_file.pkl'\n",
    "cnn = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories\"\n",
    "path_of_downloaded_files = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/Natural Language Processing/glove.6B.300d.txt\"\n",
    "filename = \"glove.6B.300d.txt\"\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "text = read_file('/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories/0a0a4c90d59df9e36ffec4ba306b4f20f3ba4acb.story')\n",
    "#text.split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def split_text(article):\n",
    "    indx = article.index('@highlight')\n",
    "    story = article[:indx]\n",
    "    highlight = article[indx:].split('@highlight')\n",
    "\n",
    "    highlight = \". \".join([h.strip() for h in highlight if len(h)>0])\n",
    "    return story,highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293d770c7c614fcb9d1e495aa457be7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def read_all(folder):\n",
    "    dataset = list()\n",
    "\n",
    "    for file in tqdm(listdir(folder)):\n",
    "        filename = folder + '/' + file\n",
    "        article = read_file(filename)\n",
    "        story,highlight = split_text(article)\n",
    "\n",
    "        dataset.append({'story':story, 'highlight':highlight})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset = read_all(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving dataset for cleaning\n",
    "import pickle\n",
    "output_file = open(unprocessed_file_name,'wb')\n",
    "pickle.dump(dataset, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count_text'] = df['story'].apply(lambda x: len(str(x).split()))\n",
    "df['highlight_count'] = df['highlight'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean word count length of text article is 654\n",
      "The mean word count length of summary/highlight is 41\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "print(\"The mean word count length of text article is \" + str(floor(df['word_count_text'].mean())))\n",
    "print(\"The mean word count length of summary/highlight is \" + str(floor(df['highlight_count'].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max word count length of text article is 1879\n",
      "The max word count length of summary/highlight is 106\n"
     ]
    }
   ],
   "source": [
    "max_article_len = floor(df['word_count_text'].max())\n",
    "max_summary_len = floor(df['highlight_count'].max())\n",
    "print(\"The max word count length of text article is \" + str(max_article_len))\n",
    "print(\"The max word count length of summary/highlight is \" + str(max_summary_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "stories = df['story'].tolist()\n",
    "summaries = df['highlight'].tolist()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "# populate the lists with sentence lengths\n",
    "for i in stories:\n",
    "      text_word_count.append(len(i.split()))\n",
    "for i in summaries:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('word_count_text', axis=1, inplace=True)\n",
    "df.drop('highlight_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "story        0\n",
       "highlight    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase): \n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase) \n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)  \n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)  \n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)  \n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)  \n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)  \n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)  \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb04b94e2924524bd514d57f5cda37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb658eed4b84baf8c77d77ab0ba91eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_text(data):\n",
    "    article_text = []\n",
    "    \n",
    "    for i in tqdm(data):\n",
    "        dash_indx = i.find('(CNN) --')\n",
    "        if dash_indx>=0: #and dash_indx<=20:\n",
    "            i = i[dash_indx+len('(CNN) --'):]\n",
    "        tt = re.sub(r'\\n',' ', i)\n",
    "        tt=re.sub(r\"([?!¿])\", r\" \\1 \", tt)\n",
    "        tt=decontracted(tt)\n",
    "        tt = re.sub('[^A-Za-z0-9.,]+', ' ', tt)\n",
    "        tt = tt.lower()\n",
    "        article_text.append(tt)\n",
    "    return article_text\n",
    "\n",
    "\n",
    "clean_article = clean_text(stories)\n",
    "clean_summary = clean_text(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['story'] = clean_article\n",
    "df['highlight'] = clean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "story        0\n",
       "highlight    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(cleaned_file_name,'wb')\n",
    "pickle.dump(df, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df))\n",
    "test_size = len(df) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(df, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-0c6d93aa8805>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 400000 word vectors from glove.6B.300d.txt.\n"
     ]
    }
   ],
   "source": [
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(filename)\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "print('loaded %s word vectors from %s.' % (len(word_vectors.key_to_index),filename ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7fffde363a495fa9704ca391ae7404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_word_corpus = []\n",
    "for article in tqdm(train_dataset.dataset['story']):\n",
    "    train_word_corpus.extend(word_tokenize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67923886\n",
      "253371\n",
      "160545\n",
      "The number of words that are present in both glove vectors and our corpus are 160545 which is nearly 63.0% \n"
     ]
    }
   ],
   "source": [
    "print(len(train_word_corpus))\n",
    "unique_word_corpus = set(train_word_corpus)\n",
    "unique_word_corpus_len = len(unique_word_corpus)\n",
    "print(unique_word_corpus_len)\n",
    "inter_word = set(word_vectors.key_to_index).intersection(unique_word_corpus)\n",
    "print(len(inter_word))\n",
    "print(\"The number of words that are present in both glove vectors and our corpus are {} which \\\n",
    "is nearly {}% \".format(len(inter_word), np.round((float(len(inter_word))/len(unique_word_corpus))\n",
    "*100)))\n",
    "out_of_embd_word = unique_word_corpus.difference(set(word_vectors.key_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "63% seems reseaonable as most of the words out of the word_vocab are either number, proper noun or spelling mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [] \n",
    "word2indx = {}\n",
    "indx2word = {}\n",
    "\n",
    "with open(path_of_downloaded_files) as f:\n",
    "    for indx,l in enumerate(f):\n",
    "        line = l.split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2indx[word] = indx\n",
    "        indx2word[indx]=word\n",
    "\n",
    "glove = {w: word_vectors[word2indx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_len = len(unique_word_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weights(unique_word_corpus,glove):\n",
    "    matrix_len = len(unique_word_corpus)\n",
    "    unique_word2indx = {}\n",
    "\n",
    "\n",
    "    weight_matrix  = np.zeros((matrix_len, embedding_dim))\n",
    "    words_found = 0\n",
    "\n",
    "    for indx, word in enumerate(unique_word_corpus):\n",
    "        try:\n",
    "            unique_word2indx[word] = indx\n",
    "            weight_matrix[indx] = glove[word]\n",
    "            words_found +=1\n",
    "        except KeyError:\n",
    "            weight_matrix[indx] = np.random.normal(scale=0.6 , size= (embedding_dim,))\n",
    "            unique_word2indx[word] = indx\n",
    "    \n",
    "    return torch.from_numpy(weight_matrix), unique_word2indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_matrix, unique_word2indx = generate_weights(unique_word_corpus,glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'words': words,\n",
    "    'word2indx': word2indx,\n",
    "    'weight_matrix' : weight_matrix,\n",
    "    'unique_word2indx' : unique_word2indx,\n",
    "    'indx2word' : indx2word,\n",
    "    'glove' : glove\n",
    "}\n",
    "\n",
    "with open(\"vocab.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(all_info_want_to_save, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weight_matrix, non_trainable = False):\n",
    "    num_embeddings, embedding_dim = weight_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings,embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weight_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer,num_embeddings,embedding_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2tensor(word):\n",
    "    indx = unique_word2indx[word]\n",
    "    return weight_matrix[indx]\n",
    "\n",
    "def sequence2tensor(seq):\n",
    "    sequenceList = []\n",
    "    for word in word_tokenize(seq):\n",
    "        sequenceList.append(word2tensor(word))\n",
    "    return sequenceList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtensor = sequence2tensor(train_dataset.dataset['story'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqtensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenize(train_dataset.dataset['story'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size,weight_matrix, bidirectional = True):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.input_size = input_size\n",
    "    self.bidirectional = bidirectional\n",
    "    self.embedding, self.num_embeddings, embedding_dim = create_emb_layer(weight_matrix,True)\n",
    "    \n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, bidirectional = bidirectional)\n",
    "  \n",
    "  def forward(self, inputs, hidden):\n",
    "    inputs = self.embedding(inputs)\n",
    "    output, hidden = self.lstm(inputs.view(1, 1, self.input_size), hidden)\n",
    "    return output, hidden\n",
    "    \n",
    "  def init_hidden(self):\n",
    "    return (torch.zeros(1 + int(self.bidirectional), 1, self.hidden_size),\n",
    "      torch.zeros(1 + int(self.bidirectional), 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(seqtensor[0])\n",
    "\n",
    "hidden = encoder.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= len(word_tokenize(train_dataset.dataset['story'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-540d0c08001f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-80-aca140753eab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.DoubleTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_size,128,weight_matrix,True)\n",
    "\n",
    "out,hidden =encoder.forward(seqtensor[0],hidden)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
