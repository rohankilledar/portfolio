{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "from os import listdir\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_file_name = 'unprocessed_file.pkl'\n",
    "cleaned_file_name ='cleaned_file.pkl'\n",
    "cnn = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories\"\n",
    "path_of_downloaded_files = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/Natural Language Processing/glove.6B.50d.txt\"\n",
    "filename = \"glove.6B.50d.txt\"\n",
    "embedding_dim = 50\n",
    "data_size = 2000\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-0c6d93aa8805>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    }
   ],
   "source": [
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(filename)\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "print('loaded %s word vectors from %s.' % (len(word_vectors.key_to_index),filename ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "sos = 'sos'\n",
    "eos = 'eos'\n",
    "\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.words = []\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0  # Count SOS and EOS\n",
    "        self.glove = {}\n",
    "        self.embedding_dim = word_vectors.get_vector('office').shape[0]\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in word_tokenize(sentence):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            self.words.append(word)\n",
    "            if word not in self.glove:\n",
    "                self.glove[word] = np.random.normal(scale=0.6 , size= (self.embedding_dim,))\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def addPretrained(self,path_of_downloaded_files):\n",
    "        with open(path_of_downloaded_files) as f:\n",
    "            for indx,l in enumerate(f):\n",
    "                line = l.split()\n",
    "                word = line[0]\n",
    "                if word == sos:\n",
    "                    first_word = self.words[0]\n",
    "                    self.words.append(first_word)\n",
    "                    self.words[0] = sos\n",
    "                    self.word2index[first_word] = indx\n",
    "                    self.word2index[sos] = 0\n",
    "                    self.index2word[indx] = first_word\n",
    "                    self.index2word[0] = sos\n",
    "                    self.glove[sos] = word_vectors[indx]\n",
    "                    self.glove[first_word] = word_vectors[0]\n",
    "                    self.word2count[sos] = 1\n",
    "                    self.n_words += 1\n",
    "\n",
    "                elif word == eos:\n",
    "                    sec_word = self.words[1]\n",
    "                    self.words.append(sec_word)\n",
    "                    self.words[1] = eos\n",
    "                    self.index2word[indx] = sec_word\n",
    "                    self.index2word[1] = eos\n",
    "                    self.word2index[sec_word] = indx\n",
    "                    self.word2index[eos] = 1\n",
    "                    self.glove[eos] = word_vectors[indx]\n",
    "                    self.glove[sec_word] = word_vectors[1]\n",
    "                    self.word2count[eos] = 1\n",
    "                    self.n_words += 1\n",
    "                else:\n",
    "                    self.words.append(word)\n",
    "                    self.word2count[word] = 1\n",
    "                    self.word2index[word] = indx\n",
    "                    self.index2word[indx]=word\n",
    "                    self.glove[word] = word_vectors[indx]\n",
    "                    self.n_words += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase): \n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase) \n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)  \n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)  \n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)  \n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)  \n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)  \n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)  \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    \n",
    "    \n",
    "    dash_indx = s.find('(CNN) --')\n",
    "    if dash_indx>=0: #and dash_indx<=20:\n",
    "        s = s[dash_indx+len('(CNN) --'):]\n",
    "        \n",
    "    s=decontracted(s)\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def split_text(article):\n",
    "    indx = article.index('@highlight')\n",
    "    story = article[:indx]\n",
    "    highlight = article[indx:].split('@highlight')\n",
    "\n",
    "    highlight = \". \".join([h.strip() for h in highlight if len(h)>0])\n",
    "    return story,highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b668739fd6f4783a2c448ee47aa39af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_all(folder):\n",
    "    dataset = list()\n",
    "\n",
    "    for file in tqdm(listdir(folder)):\n",
    "        filename = folder + '/' + file\n",
    "        article = read_file(filename)\n",
    "        story,highlight = split_text(article)\n",
    "\n",
    "        dataset.append({'story':story, 'highlight':highlight})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset = read_all(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving dataset for cleaning\n",
    "import pickle\n",
    "output_file = open(unprocessed_file_name,'wb')\n",
    "pickle.dump(dataset, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_pickle(unprocessed_file_name)\n",
    "#reducing the dataset for initial testing of model\n",
    "dataset = dataset[:data_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['story'] = df['story'].apply(lambda x: normalizeString(x))\n",
    "df['highlight'] = df['highlight'].apply(lambda x: normalizeString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['highlight'] = df['highlight'].apply(lambda x: sos + \" \" + x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean word count length of text article is 689\n",
      "The mean word count length of summary/highlight is 46\n",
      "The max word count length of text article is 1884\n",
      "The max word count length of summary/highlight is 82\n"
     ]
    }
   ],
   "source": [
    "df['word_count_text'] = df['story'].apply(lambda x: len(str(x).split()))\n",
    "df['highlight_count'] = df['highlight'].apply(lambda x: len(str(x).split()))\n",
    "from math import floor\n",
    "print(\"The mean word count length of text article is \" + str(floor(df['word_count_text'].mean())))\n",
    "print(\"The mean word count length of summary/highlight is \" + str(floor(df['highlight_count'].mean())))\n",
    "\n",
    "max_article_len = floor(df['word_count_text'].max())\n",
    "max_summary_len = floor(df['highlight_count'].max())\n",
    "print(\"The max word count length of text article is \" + str(max_article_len))\n",
    "print(\"The max word count length of summary/highlight is \" + str(max_summary_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('word_count_text', axis=1, inplace=True)\n",
    "df.drop('highlight_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_data.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00ce1487c794bec9350a38b90777af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted Words:\n",
      "vocab 402650\n"
     ]
    }
   ],
   "source": [
    "vocab = Lang('vocab')\n",
    "vocab.addPretrained(path_of_downloaded_files)\n",
    "def prepareData():\n",
    "    for indx,row in tqdm(df.iterrows()):\n",
    "        vocab.addSentence(row['story'])\n",
    "        vocab.addSentence(row['highlight'])\n",
    "    print(\"counted Words:\")\n",
    "    print(vocab.name, vocab.n_words)\n",
    "prepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(df, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    # return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    return [lang.word2index[word] for word in word_tokenize(sentence)]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(vocab, pair[0])\n",
    "    target_tensor = tensorFromSentence(vocab, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_weights(unique_word_corpus,glove, tens=True):\n",
    "    matrix_len = len(unique_word_corpus)\n",
    "    unique_word2indx = {}\n",
    "    \n",
    "    weight_matrix  = np.zeros((matrix_len, embedding_dim))\n",
    "   \n",
    "    words_found = 0\n",
    "\n",
    "    for indx, word in enumerate(unique_word_corpus):\n",
    "        try:\n",
    "            unique_word2indx[word] = indx\n",
    "            weight_matrix[indx] = glove[word]\n",
    "            words_found +=1\n",
    "        except KeyError:\n",
    "            weight_matrix[indx] = np.random.normal(scale=0.6 , size= (embedding_dim,))\n",
    "            unique_word2indx[word] = indx\n",
    "    if tens:\n",
    "        return torch.from_numpy(weight_matrix) , unique_word2indx\n",
    "    else:\n",
    "        return weight_matrix,unique_word2indx\n",
    "\n",
    "weight_matrix, meh= generate_weights(vocab.words, vocab.glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5139, -0.7162, -0.2702,  ...,  0.1683,  0.5761,  0.0467],\n",
       "        [-0.3090,  0.1448,  1.1682,  ..., -0.4097, -0.4651, -0.2958],\n",
       "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
       "        ...,\n",
       "        [-0.7758, -0.6933,  0.5565,  ...,  0.2769, -0.9246, -0.0116],\n",
       "        [-0.0579,  0.5945, -0.5711,  ..., -0.3212,  0.7856,  1.3458],\n",
       "        [ 0.2870, -0.0951, -1.0401,  ..., -0.2164,  0.4428, -0.0370]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51387 , -0.71619 , -0.27022 , -0.39605 ,  0.077725, -0.51019 ,\n",
       "       -0.096037, -0.51926 ,  1.1398  , -0.48839 ,  0.55519 , -0.079659,\n",
       "        0.63065 , -0.19989 , -0.72763 , -1.1698  , -0.78838 , -0.11933 ,\n",
       "       -0.016341,  0.58433 , -0.60493 ,  0.34394 , -0.10728 ,  0.38154 ,\n",
       "        0.60439 ,  0.098549, -0.62968 , -0.55329 , -0.40243 , -0.75822 ,\n",
       "        0.58165 ,  0.8636  , -0.80085 ,  0.26178 , -1.1834  ,  0.099697,\n",
       "        0.56937 , -1.6251  ,  0.4834  ,  0.36138 ,  0.73861 , -0.65523 ,\n",
       "       -0.31002 , -0.65169 ,  0.51786 ,  0.39711 ,  0.22438 ,  0.16832 ,\n",
       "        0.57609 ,  0.046694], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.glove['sos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28069\n",
      "tensor([28069])\n",
      "tensor([[ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "         -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "          2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "          1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "         -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "         -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "          4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "          7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "         -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "          1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01]],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "word = 'the'\n",
    "embeds = nn.Embedding(vocab.n_words, embedding_dim)  # 2 words in vocab, 5 dimensional embeddings\n",
    "embeds =embeds.from_pretrained(weight_matrix)\n",
    "lookup_tensor = torch.tensor([vocab.word2index[word]], dtype=torch.long)\n",
    "print(vocab.word2index[word])\n",
    "print(lookup_tensor)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n",
    "print(weight_matrix[vocab.word2index[word]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = 1\n",
    "\n",
    "       # self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(num_embeddings = vocab.n_words,embedding_dim= embedding_dim)\n",
    "        self.embedding = self.embedding.from_pretrained(weight_matrix)\n",
    "        #self.embedding.from_pretrained(glove)\n",
    "        self.lstm = nn.LSTM(input_size = hidden_dim, hidden_size = hidden_dim) #, num_layers = 1, bidirectional = True, batch_first = True)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = embedded.float()\n",
    "       # print(output)\n",
    "        #print(hidden)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        #in case of LSTM we need h0 and c0 hence init this as a tuple (h0,c0) and passed as hidden to lstm and in case of gru its just h0\n",
    "       return (torch.zeros(self.num_layer, 1, self.hidden_size, dtype=torch.float, device=device), torch.zeros(self.num_layer,1,self.hidden_size,dtype = torch.float, device= device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings= output_size,embedding_dim= hidden_size)\n",
    "        self.embedding.from_pretrained(weight_matrix)\n",
    "        self.lstm = nn.LSTM(input_size= hidden_size, hidden_size= hidden_size) #, num_layers = 1, bidirectional = False, batch_first = True)\n",
    "        #self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.fc = nn.Linear(in_features= hidden_size , out_features=vocab.n_words)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output = F.relu(embedded)\n",
    "        \n",
    "        #hidden is [2,1,50]\n",
    "        #emb is [1,1,50]\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        #output = self.softmax(self.out(output[0]))\n",
    "        output = self.fc(output[0])\n",
    "        \n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_article_len):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.embedding.from_pretrained(weight_matrix)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "       \n",
    "    \n",
    "        AttnDecoderRNN.embedded = embedded\n",
    "        \n",
    "        AttnDecoderRNN.hidden = hidden\n",
    "        AttnDecoderRNN.encoder_outputs = encoder_outputs\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0].view(1,-1)), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "                                 \n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "       return (torch.zeros(1, 1, self.hidden_size, dtype=torch.int64, device=device), torch.zeros(1,1,self.hidden_size,dtype = torch.int64, device= device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# def indexesFromSentence(lang, sentence):\n",
    "#     #return [lang.glove[word] for word in sentence.split(' ')]\n",
    "#     return [lang.word2index[word] for word in word_tokenize(sentence)]\n",
    "#     #return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_token)\n",
    "#     # indexes.append(lang.glove[eos])\n",
    "#     #change it to include glove values\n",
    "#     #return indexes\n",
    "#     return torch.Tensor(indexes,dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(vocab, pair[0])\n",
    "#     target_tensor = tensorFromSentence(vocab, pair[1])\n",
    "#     return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, attn, max_length=vocab.n_words):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if attn :\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden= decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                #tar_tens = weight_matrix[target_tensor[di].item()].view(-1).float()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            if attn :\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden= decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            tar_tens = weight_matrix[target_tensor[di].item()].view(-1).float()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    \n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, attn=False, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    if attn:\n",
    "        print(\"training with attention.\")\n",
    "    print(start)\n",
    "\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    print('encoder optimizer init')\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    print('decoder optimizer init')\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print('choosing training pairs:' + str(n_iters))\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    print('init criterion')\n",
    "    criterion = nn.NLLLoss()\n",
    "    # criterion = nn.MSELoss()\n",
    "    \n",
    "    print('starting iterations')\n",
    "    \n",
    "    for iter in tqdm(range(1, n_iters + 1)):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, attn)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                     for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = training_pairs[1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5139, -0.7162, -0.2702, -0.3961,  0.0777, -0.5102, -0.0960, -0.5193,\n",
      "         1.1398, -0.4884,  0.5552, -0.0797,  0.6306, -0.1999, -0.7276, -1.1698,\n",
      "        -0.7884, -0.1193, -0.0163,  0.5843, -0.6049,  0.3439, -0.1073,  0.3815,\n",
      "         0.6044,  0.0985, -0.6297, -0.5533, -0.4024, -0.7582,  0.5817,  0.8636,\n",
      "        -0.8008,  0.2618, -1.1834,  0.0997,  0.5694, -1.6251,  0.4834,  0.3614,\n",
      "         0.7386, -0.6552, -0.3100, -0.6517,  0.5179,  0.3971,  0.2244,  0.1683,\n",
      "         0.5761,  0.0467])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8186, -12.7180, -12.8709,  ..., -12.9178, -12.8003, -12.8327]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "actonel\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(12.8186, grad_fn=<AddBackward0>)\n",
      "tensor([-0.3709,  0.4529, -0.0232,  0.4171, -0.4578, -0.4408, -0.1500,  0.2986,\n",
      "        -0.3741, -0.3409,  0.3776,  0.0050,  0.3546,  0.8761, -0.1974,  0.0247,\n",
      "        -0.3890,  0.9281,  0.0592,  0.8742,  0.5247,  0.2272,  0.2016, -0.3262,\n",
      "         0.5885, -2.1577,  0.1074, -0.1838, -0.6022, -0.1849,  3.1231, -0.4460,\n",
      "         0.1297,  1.1880,  0.1762, -0.2729, -0.1376, -0.6049, -1.4584, -0.4424,\n",
      "        -0.7418, -0.7988,  1.1227, -0.7800,  1.7246, -1.0448, -0.2536,  0.9528,\n",
      "        -0.4706, -0.7522])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8954, -12.7146, -12.8466,  ..., -12.9397, -12.8130, -12.7695]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "exoplanets\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(25.4600, grad_fn=<AddBackward0>)\n",
      "tensor([-1.0862,  0.5254, -0.4419,  0.1168, -0.2416,  0.6224, -0.9757, -0.0655,\n",
      "        -0.3374,  2.3043,  0.3768, -0.0691,  0.1264,  1.3754,  0.4197, -0.4031,\n",
      "         0.0657, -0.3436, -0.0282, -0.4924,  0.1347,  0.9913,  0.3141,  1.0062,\n",
      "         0.2042, -0.5223, -1.6195,  0.0161,  0.4174, -0.5017,  2.6966, -0.5328,\n",
      "         0.6230,  0.5380, -0.0174, -0.1543,  0.0629, -0.5222, -0.3278, -0.5334,\n",
      "         0.3708,  0.5679, -0.3936, -0.5166,  0.2692,  0.2931, -0.0162, -0.9825,\n",
      "        -0.6489, -0.0649])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8642, -12.8487, -12.8020,  ..., -13.0571, -12.8104, -12.7615]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "great-grandsons\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(38.4255, grad_fn=<AddBackward0>)\n",
      "tensor([-0.7499,  0.6935, -1.4680,  0.4642,  0.3709, -0.3769, -0.4513, -1.2805,\n",
      "        -0.6060,  0.4893,  0.6516,  0.0240,  0.5999,  0.1752,  0.1481,  0.3365,\n",
      "         0.2548,  0.2399,  0.5926,  0.6564,  0.0045,  0.4239, -0.5368,  0.6038,\n",
      "         0.8440, -1.1633, -1.5413, -0.4296,  0.1706,  0.3034,  2.9316, -0.1449,\n",
      "         0.0201, -0.8996, -1.1567,  0.3065, -1.1955,  0.0477, -0.1241,  0.7999,\n",
      "        -0.1209,  0.1279,  0.1748,  0.5059,  0.5193,  0.3303, -0.2117, -0.0460,\n",
      "         0.2691, -0.6687])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8599, -12.8640, -12.7936,  ..., -12.9849, -12.9148, -12.6976]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "45.70\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(51.4692, grad_fn=<AddBackward0>)\n",
      "tensor([-0.7045,  0.5703, -0.6236,  0.7701, -0.2869,  0.4521, -0.0817,  0.5431,\n",
      "         0.3653,  1.4758,  0.9023, -0.2626, -0.2828,  0.3777,  0.7189, -0.1996,\n",
      "        -0.5697,  0.0042, -0.6926,  0.1108, -0.8521,  0.8993, -0.2735,  0.4511,\n",
      "         0.9898, -0.6023, -0.4961,  0.0087,  0.4697,  0.1633,  1.4850,  0.3504,\n",
      "         0.8960, -0.1022, -0.4958,  0.3188, -0.3224, -0.1772,  0.2016, -0.7319,\n",
      "         0.4209,  0.4579, -0.4751, -0.0032,  0.9807, -0.2354,  0.8433, -0.4462,\n",
      "         0.0500, -0.2875])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.9827, -12.8440, -12.9352,  ..., -12.8821, -12.9263, -12.7723]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "pegula\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(64.3057, grad_fn=<AddBackward0>)\n",
      "tensor([ 8.1544e-01,  3.0171e-01,  5.4720e-01,  4.6581e-01,  2.8531e-01,\n",
      "        -5.6112e-01, -4.3913e-01, -9.0877e-03,  1.0002e-01, -1.7218e-01,\n",
      "         2.8133e-01,  3.7672e-01, -4.0756e-01,  1.5836e-01,  8.9113e-01,\n",
      "         1.2997e+00,  5.1508e-01, -1.9480e-01,  5.1856e-02, -9.3380e-01,\n",
      "         6.9955e-02, -2.4876e-01, -1.6723e-02, -2.0310e-01, -3.3558e-02,\n",
      "        -1.8132e+00,  1.1199e-01, -3.1961e-01, -1.3746e-01, -4.5499e-01,\n",
      "         3.8856e+00,  1.2140e+00, -1.0046e+00, -5.6274e-02,  3.8776e-03,\n",
      "        -4.0669e-01,  2.9452e-01,  3.0171e-01,  3.8848e-02, -5.6088e-01,\n",
      "        -4.6582e-01,  1.7155e-01,  3.3729e-01, -1.5247e-01,  2.3771e-02,\n",
      "         5.1415e-01, -2.1759e-01,  3.1965e-01, -3.4741e-01,  4.1672e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-13.0346, -12.9130, -12.8648,  ..., -12.9033, -12.7396, -12.8476]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "monosodium\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(77.3542, grad_fn=<AddBackward0>)\n",
      "tensor([ 9.1102e-01, -2.2872e-01,  2.0770e-01, -2.0237e-01,  5.0697e-01,\n",
      "        -5.7893e-02, -4.1729e-01, -7.5341e-02, -3.0454e-01, -3.2860e-03,\n",
      "         4.4481e-01,  4.1818e-01, -3.3409e-01,  3.2917e-02,  9.8872e-01,\n",
      "         9.1984e-01,  4.0521e-01,  1.9250e-02, -1.0520e-01, -7.9865e-01,\n",
      "        -3.6403e-01, -8.7995e-02,  7.2182e-01,  1.1114e-01,  2.1530e-01,\n",
      "        -1.9411e+00, -2.6376e-01,  4.4550e-01,  2.7586e-01, -2.1104e-01,\n",
      "         4.0212e+00, -6.1943e-02, -3.2134e-01, -8.1922e-01,  2.1080e-01,\n",
      "        -2.0414e-01,  7.2625e-01,  4.7517e-01, -3.9853e-01, -3.9168e-01,\n",
      "        -3.4581e-01,  2.5928e-02,  1.3072e-01,  7.3562e-01, -1.5199e-01,\n",
      "        -1.8439e-01, -6.7128e-01,  1.6692e-01, -5.0063e-02,  1.9241e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8571, -12.9257, -12.9252,  ..., -12.9211, -12.8133, -12.9088]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "footway\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(90.1002, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3004,  0.2501, -0.1669,  0.1923,  0.0269, -0.0795, -0.9138, -0.1974,\n",
      "        -0.0534, -0.4085, -0.2684, -0.2821, -0.5000,  0.1221,  0.3903,  0.1780,\n",
      "        -0.4429, -0.4048, -0.9505, -0.1690,  0.7779,  0.3352,  0.3346, -0.1754,\n",
      "        -0.1202, -1.7861,  0.2924,  0.5593,  0.0300, -0.3242,  3.9297,  0.1088,\n",
      "        -0.5734, -0.1784,  0.0042, -0.1631,  0.4508, -0.1612, -0.1731, -0.0879,\n",
      "        -0.0890,  0.0620, -0.1995, -0.3886, -0.1823,  0.0608,  0.0986, -0.0713,\n",
      "         0.2305, -0.5194])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8681, -12.9703, -12.8080,  ..., -12.8949, -12.9215, -12.8011]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "veronica\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(103.0007, grad_fn=<AddBackward0>)\n",
      "tensor([-0.0346,  0.4109, -0.0974, -0.1955, -0.0586, -0.2581, -0.8514,  0.1958,\n",
      "        -0.7683,  0.3704, -0.6391,  0.3059, -0.3812,  0.4051,  0.9092,  0.5436,\n",
      "        -0.0889,  0.1742,  0.3359, -0.3681,  0.3240,  1.0560,  0.6870,  0.8126,\n",
      "         0.7417, -1.7618, -0.0853,  0.3456,  0.5537, -0.2403,  2.8321,  0.8073,\n",
      "        -0.5928, -0.5213, -0.6004, -0.3917, -0.2712, -0.5201, -0.4718, -0.4678,\n",
      "        -0.0462,  0.3937, -0.7887,  0.4317,  0.5205,  0.0280, -0.0139,  0.5620,\n",
      "        -0.5977,  0.9507])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.9629, -12.9545, -12.8670,  ..., -12.9588, -12.8858, -12.8680]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "diego\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(115.7874, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5633,  0.3588, -0.1462,  0.9526,  0.2372, -1.0129, -0.1875, -0.9313,\n",
      "         0.7940, -0.4640,  0.4457,  0.2595, -0.3392,  0.2449,  0.3580,  0.7320,\n",
      "         0.0393, -0.1458, -0.6524,  0.7171,  0.6620, -0.3812,  0.1997,  0.1868,\n",
      "         0.3275, -1.0706, -0.0599, -0.3618, -0.5865,  0.7648,  3.1661,  0.9717,\n",
      "         1.3140,  0.0458, -0.7731, -0.9021, -1.4190, -0.0807, -0.9045, -0.1324,\n",
      "        -1.1106, -0.0914,  1.2981, -0.8006,  0.6032,  0.7401, -0.0736, -0.0474,\n",
      "        -0.0868, -0.0862])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8783, -13.0101, -12.9222,  ..., -12.9495, -12.9115, -12.9163]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "helfgot\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(128.4853, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4367, -0.0551, -0.1878, -0.4187, -0.0359,  0.2403, -1.2174,  0.3900,\n",
      "        -0.8019, -0.4400,  0.4690,  0.4315, -0.7940, -0.3252,  0.5626,  0.0141,\n",
      "        -0.7527, -0.2726, -0.9521,  0.2824,  0.4957,  0.2468,  0.5759, -0.1742,\n",
      "         0.1652, -1.7485, -0.1366, -0.1741, -0.4340, -0.2042,  3.0914, -0.6491,\n",
      "        -0.1833, -0.5821,  0.2914,  0.1273,  0.5774,  0.3082, -0.0974,  0.0178,\n",
      "         0.0314,  0.0097, -0.5900, -0.6016, -0.2733, -0.0231, -0.2561, -0.6963,\n",
      "        -0.2053, -0.5019])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.6760, -12.9196, -12.8850,  ..., -12.9375, -12.9222, -12.9272]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "200k\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(141.5441, grad_fn=<AddBackward0>)\n",
      "tensor([ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
      "         2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
      "        -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
      "         3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
      "        -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
      "        -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
      "         4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
      "        -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
      "        -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
      "         2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.7143, -13.0145, -12.8609,  ..., -12.8951, -12.9168, -12.9336]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "mount\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(154.5050, grad_fn=<AddBackward0>)\n",
      "tensor([ 4.6281e-01,  4.1144e-04,  3.2206e-01,  5.2119e-02,  2.5740e-01,\n",
      "        -2.0206e-01, -9.5958e-01,  8.0315e-02,  7.1420e-02, -1.8973e-01,\n",
      "        -2.9623e-01, -1.0933e+00, -3.9617e-01, -1.9416e-01,  1.6158e+00,\n",
      "         2.0214e-01, -8.9728e-01, -6.2867e-01, -7.0070e-01,  1.9352e-01,\n",
      "         8.5183e-01,  1.1041e-01,  1.5913e-01, -5.6004e-01, -6.2643e-01,\n",
      "        -1.7449e+00,  5.1275e-01,  2.5222e-02, -4.0847e-01,  8.0248e-01,\n",
      "         3.4200e+00,  3.1542e-01, -3.8810e-01,  4.6212e-01,  2.8418e-01,\n",
      "        -6.0805e-01,  2.7313e-01,  3.3328e-02,  2.0980e-02, -4.9465e-01,\n",
      "        -8.6607e-01,  3.1712e-01, -4.1658e-03, -3.8582e-01,  7.1257e-02,\n",
      "        -2.6801e-01, -2.1712e-01,  6.1648e-01, -2.3407e-01, -1.3272e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8065, -12.9394, -12.8747,  ..., -12.8950, -12.7685, -12.8996]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "venkataraghvan\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(167.2386, grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5164e-01,  3.0177e-01, -1.6763e-01,  1.7684e-01,  3.1719e-01,\n",
      "         3.3973e-01, -4.3478e-01, -3.1086e-01, -4.4999e-01, -2.9486e-01,\n",
      "         1.6608e-01,  1.1963e-01, -4.1328e-01, -4.2353e-01,  5.9868e-01,\n",
      "         2.8825e-01, -1.1547e-01, -4.1848e-02, -6.7989e-01, -2.5063e-01,\n",
      "         1.8472e-01,  8.6876e-02,  4.6582e-01,  1.5035e-02,  4.3474e-02,\n",
      "        -1.4671e+00, -3.0384e-01, -2.3441e-02,  3.0589e-01, -2.1785e-01,\n",
      "         3.7460e+00,  4.2284e-03, -1.8436e-01, -4.6209e-01,  9.8329e-02,\n",
      "        -1.1907e-01,  2.3919e-01,  1.1610e-01,  4.1705e-01,  5.6763e-02,\n",
      "        -6.3681e-05,  6.8987e-02,  8.7939e-02, -1.0285e-01, -1.3931e-01,\n",
      "         2.2314e-01, -8.0803e-02, -3.5652e-01,  1.6413e-02,  1.0216e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.7062, -12.8964, -12.8123,  ..., -12.9258, -12.7671, -12.7780]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "herkules\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(180.0509, grad_fn=<AddBackward0>)\n",
      "tensor([-0.0988,  0.2698,  0.3530, -0.1073, -0.0152,  0.0534, -1.0824, -0.5300,\n",
      "         0.0095,  0.0704, -0.0892, -0.6267, -0.5266, -0.5657,  1.8044,  0.0169,\n",
      "        -0.4487, -0.0415, -1.1136,  0.1749,  0.4956, -0.3824,  0.3018, -0.7067,\n",
      "        -0.3589, -1.5164, -0.0244, -0.5411, -0.3616,  0.5280,  3.6553,  0.7121,\n",
      "        -0.1699,  0.3637,  0.3399, -0.4819,  0.1094,  0.6143,  0.1570, -0.7072,\n",
      "        -1.2359, -0.0143,  0.0956, -0.3063, -0.4974, -0.0494, -0.1670,  0.1197,\n",
      "        -0.3751,  0.0983])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.7798, -12.8998, -12.8112,  ..., -12.9387, -12.6578, -12.6851]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "repubblica\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(192.8755, grad_fn=<AddBackward0>)\n",
      "tensor([-0.4853,  0.9838, -0.2903, -0.3308,  0.7467,  0.5992, -1.4261,  0.0849,\n",
      "        -0.2533, -0.1080, -0.0736, -0.2404, -0.6001,  0.2772,  0.6128,  0.0773,\n",
      "        -0.4800,  0.5070,  0.1302,  0.6652, -0.8458,  0.9411, -1.0953,  0.4036,\n",
      "         0.1651, -2.5206, -0.1682,  0.2054,  0.2047,  0.0744,  2.7209, -0.7090,\n",
      "        -0.0495,  0.9631,  0.7211,  0.5529, -0.1386,  0.5980,  0.5836, -0.4216,\n",
      "        -0.2174,  0.3613,  0.1828,  0.3306,  0.5875,  0.1003, -0.1622, -0.9594,\n",
      "         0.0384, -0.7330])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8439, -12.9131, -12.8970,  ..., -12.8654, -12.8100, -12.7085]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "kada\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(205.7234, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.5482,  0.0388,  0.1013,  0.3132,  0.0955,  0.4181, -0.7949, -0.5830,\n",
      "         0.0266,  0.1239,  0.3519, -0.0216, -0.8702, -0.2718,  0.6545,  0.4293,\n",
      "         0.0975,  0.3178, -0.1192, -0.0971, -0.4758,  0.2491,  0.1223, -0.2908,\n",
      "        -0.1687, -2.1072,  0.0222,  0.4528, -0.6449,  0.1318,  3.6594, -0.1714,\n",
      "         0.2392, -0.4225, -0.0883, -0.3293, -0.1285,  0.4706, -0.0760, -0.2775,\n",
      "        -0.4191,  0.6080, -0.2426,  0.0149, -0.2320,  0.0209, -0.8217,  0.2659,\n",
      "        -0.4027, -0.1711])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8525, -12.9188, -12.8524,  ..., -12.8405, -12.8127, -12.7816]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "yurgens\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(218.6610, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1451, -0.1344,  0.2695, -0.4600,  0.1449, -0.2399, -1.0524,  0.3754,\n",
      "        -0.2709,  0.1344, -0.3819,  0.0138, -0.7491,  0.1672,  1.1632,  0.1230,\n",
      "         0.2307, -0.0411, -0.2091,  0.0082, -0.1651,  0.4647,  0.4905,  0.1229,\n",
      "         0.4837, -1.4362, -0.5622,  0.2458,  1.0021, -0.3370,  2.5794,  0.3749,\n",
      "         0.0551, -0.0567, -0.1279,  0.1572, -0.0868,  0.1954,  0.2415, -0.4992,\n",
      "        -0.8896, -0.1562, -0.0187,  0.4349, -0.0903,  0.0575, -0.2757, -0.4089,\n",
      "        -0.2428, -0.0549])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.7660, -12.9918, -12.8619,  ..., -12.9573, -12.7932, -12.8318]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "toia\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(231.6442, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.4104,  0.1134,  0.0515, -0.5383, -0.1291,  0.2225, -0.9494, -0.1896,\n",
      "        -0.3662, -0.0670,  0.1936, -0.3304,  0.1161, -0.5859,  0.3611,  0.1256,\n",
      "        -0.3581, -0.0232, -1.2319,  0.2338,  0.7126,  0.1482,  0.5087, -0.1231,\n",
      "        -0.2035, -1.8200,  0.2229,  0.0203, -0.0817, -0.2748,  3.7343, -0.0187,\n",
      "        -0.0845, -0.3036,  0.2796,  0.0433, -0.2462,  0.0154,  0.4975,  0.1511,\n",
      "        -0.0162,  0.4013,  0.2307, -0.1074, -0.3663, -0.0511,  0.0415, -0.3606,\n",
      "        -0.1962, -0.8107])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8341, -12.7947, -12.8563,  ..., -12.9296, -12.9907, -12.8618]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "allofs\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(244.4461, grad_fn=<AddBackward0>)\n",
      "tensor([-3.5498e-01, -4.5145e-02,  1.2667e+00,  9.6886e-02, -6.0099e-01,\n",
      "         3.6053e-01, -1.6988e+00,  4.9342e-01,  2.7406e-01,  1.9291e-01,\n",
      "         6.9268e-01,  9.9941e-01, -2.8713e-01,  8.2614e-01, -1.4767e-01,\n",
      "        -1.5115e-01,  9.8193e-05, -2.4977e-01, -4.8288e-03, -7.2970e-01,\n",
      "        -9.6673e-01, -2.8784e-01, -6.2414e-01, -9.4858e-02,  1.3208e-01,\n",
      "        -4.5696e-01,  7.1463e-01, -3.9002e-01,  8.0150e-01, -6.8875e-01,\n",
      "         2.1201e+00,  2.6419e-02,  3.6254e-01, -5.3897e-01,  1.1154e+00,\n",
      "         1.5436e+00,  1.0456e+00,  2.6522e-01,  2.4102e-01, -9.8976e-02,\n",
      "         6.4414e-01,  7.2386e-01, -7.5275e-01, -4.9389e-02, -4.1979e-01,\n",
      "        -3.2329e-02,  3.5919e-01,  3.8111e-01, -5.8495e-01,  9.4803e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8331, -12.8306, -12.8300,  ..., -12.8768, -12.9067, -12.8953]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "headways\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(257.3039, grad_fn=<AddBackward0>)\n",
      "tensor([-0.7907,  1.0783, -1.2823, -0.1576,  0.1149,  0.8797, -0.1839,  0.5710,\n",
      "        -0.5057,  0.9006,  1.1000,  0.0687, -0.0107,  1.4153,  0.1948, -0.4034,\n",
      "         0.5286,  0.9683, -0.7118, -0.5368,  0.2074,  1.2831, -0.6150,  0.6028,\n",
      "         0.4042, -0.7391, -0.6979, -0.1663, -0.3204, -0.2516,  1.0479, -0.0964,\n",
      "         0.0078,  0.3233,  0.3582,  0.1736, -0.0728,  0.5589,  0.0529, -0.3425,\n",
      "        -0.1553,  0.6587, -0.0401, -0.7013,  0.0810, -1.5799,  0.3065, -1.8989,\n",
      "        -0.5192,  0.5053])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8536, -12.8289, -12.8734,  ..., -12.8477, -12.9547, -12.9785]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "drinks\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(270.1227, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6805, -0.0393,  0.3019, -0.1779,  0.4296,  0.0322, -0.4138,  0.1323,\n",
      "        -0.2985, -0.0853,  0.1712,  0.2242, -0.1005, -0.4365,  0.3342,  0.6785,\n",
      "         0.0572, -0.3445, -0.4279, -0.4327,  0.5596,  0.1003,  0.1868, -0.2685,\n",
      "         0.0373, -2.0932,  0.2217, -0.3987,  0.2091, -0.5573,  3.8826,  0.4747,\n",
      "        -0.9566, -0.3779,  0.2087, -0.3275,  0.1275,  0.0884,  0.1635, -0.2163,\n",
      "        -0.0944,  0.0183,  0.2105, -0.0309, -0.1972,  0.0823, -0.0943, -0.0733,\n",
      "        -0.0647, -0.2604])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8120, -12.9153, -12.7636,  ..., -12.9468, -12.8895, -12.8432]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "replenish\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(283.0227, grad_fn=<AddBackward0>)\n",
      "tensor([-1.2758e-01,  6.3400e-03, -4.1712e-01, -4.0872e-01, -1.4783e-01,\n",
      "         2.4152e-01, -7.3754e-01,  6.3143e-02, -6.0675e-01,  8.3000e-02,\n",
      "        -2.1940e-01,  7.8223e-02, -2.7765e-01,  6.0430e-01,  7.8671e-01,\n",
      "        -2.4420e-01, -5.1904e-01, -2.2198e-01, -3.8463e-01, -2.9659e-01,\n",
      "         3.0544e-01,  2.7419e-01,  1.1790e+00,  7.4396e-01, -2.2553e-01,\n",
      "        -6.5778e-01, -4.7032e-01,  4.5433e-01, -1.8491e-01,  8.7581e-02,\n",
      "         2.0002e+00,  1.3517e-01,  6.0315e-01, -1.2642e+00, -3.0328e-01,\n",
      "         2.4517e-01,  1.8794e-01,  2.1194e-01, -1.3199e+00, -8.0437e-01,\n",
      "        -4.3518e-02,  1.4564e-01, -5.5825e-01, -1.3591e-03, -1.4056e-02,\n",
      "        -4.4587e-03, -3.1234e-01, -4.6868e-01, -2.2926e-01,  1.9415e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8112, -12.8275, -12.8762,  ..., -12.8283, -12.8587, -12.8794]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "(817)\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(295.9851, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.3304,  0.2500, -0.6087,  0.1092,  0.0364,  0.1510, -0.5508, -0.0742,\n",
      "        -0.0923, -0.3282,  0.0960, -0.8227, -0.3672, -0.6701,  0.4291,  0.0165,\n",
      "        -0.2357,  0.1286, -1.0953,  0.4333,  0.5707, -0.1036,  0.2042,  0.0783,\n",
      "        -0.4279, -1.7984, -0.2786,  0.1195, -0.1269,  0.0317,  3.8631, -0.1779,\n",
      "        -0.0824, -0.6270,  0.2650, -0.0572, -0.0735,  0.4610,  0.3086,  0.1250,\n",
      "        -0.4861, -0.0080,  0.0312, -0.3658, -0.4270,  0.4216, -0.1167, -0.5070,\n",
      "        -0.0273, -0.5329])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8165, -12.9312, -12.8392,  ..., -12.9295, -12.8518, -12.8587]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "sherwen\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(308.8401, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0812,  0.8369, -0.2917,  0.0877, -0.2587, -0.2425, -0.8532, -0.5837,\n",
      "        -0.5010,  1.1290, -0.9078, -0.0323, -0.3076,  0.8460,  1.0326,  0.0370,\n",
      "         0.4837,  0.6357, -0.5392, -0.2955,  0.7871,  0.5689, -0.4529,  0.7889,\n",
      "        -0.4606, -1.4326, -1.4407,  0.2240,  0.2193, -0.5199,  1.6179,  0.0955,\n",
      "         0.2446, -0.8137, -0.2321, -0.0611, -0.5581, -0.3064, -0.4527, -1.1487,\n",
      "        -0.4231,  0.9235, -0.0907,  0.1584, -0.5646, -0.2105, -0.1200, -1.1921,\n",
      "        -0.7770,  0.6396])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.9482, -12.8396, -12.7830,  ..., -12.7462, -12.7308, -12.8084]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "messiah\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(321.7377, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1468, -0.0173, -0.3010, -0.3130, -0.2613,  0.4536, -0.3525, -1.5561,\n",
      "        -0.3393,  1.5599, -0.0961,  0.7302, -0.2700,  0.9994,  1.1585, -0.6158,\n",
      "         0.4835,  0.7396, -1.0285,  0.0427,  1.2959,  0.4910,  0.9327,  0.4090,\n",
      "        -0.0326, -0.6211, -1.8458, -0.4422, -0.3842, -0.6377,  2.3785, -0.0039,\n",
      "         0.6228, -0.8476, -0.0967,  0.6040, -0.0832, -0.0913, -1.4773, -0.7233,\n",
      "        -0.2892,  0.8748,  0.2390, -0.9307, -0.9090, -0.0450, -0.0999, -0.7708,\n",
      "        -0.6877,  0.4015])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8313, -12.8478, -12.8071,  ..., -12.7949, -12.7616, -12.8492]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "78.50\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(334.6010, grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5164e-01,  3.0177e-01, -1.6763e-01,  1.7684e-01,  3.1719e-01,\n",
      "         3.3973e-01, -4.3478e-01, -3.1086e-01, -4.4999e-01, -2.9486e-01,\n",
      "         1.6608e-01,  1.1963e-01, -4.1328e-01, -4.2353e-01,  5.9868e-01,\n",
      "         2.8825e-01, -1.1547e-01, -4.1848e-02, -6.7989e-01, -2.5063e-01,\n",
      "         1.8472e-01,  8.6876e-02,  4.6582e-01,  1.5035e-02,  4.3474e-02,\n",
      "        -1.4671e+00, -3.0384e-01, -2.3441e-02,  3.0589e-01, -2.1785e-01,\n",
      "         3.7460e+00,  4.2284e-03, -1.8436e-01, -4.6209e-01,  9.8329e-02,\n",
      "        -1.1907e-01,  2.3919e-01,  1.1610e-01,  4.1705e-01,  5.6763e-02,\n",
      "        -6.3681e-05,  6.8987e-02,  8.7939e-02, -1.0285e-01, -1.3931e-01,\n",
      "         2.2314e-01, -8.0803e-02, -3.5652e-01,  1.6413e-02,  1.0216e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8586, -12.8966, -12.9237,  ..., -12.8122, -12.7926, -13.0107]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "quintet\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(347.5247, grad_fn=<AddBackward0>)\n",
      "tensor([-0.2025,  0.2188, -0.1590,  0.5172, -1.7501, -0.6797, -0.2853,  1.1704,\n",
      "         0.8166,  0.1271, -0.2708, -0.7976,  0.6779, -0.5211,  0.5279,  0.3036,\n",
      "        -0.1110, -0.7309, -1.2799, -1.3030, -0.6715,  0.2164,  1.0570, -0.8284,\n",
      "         1.1664, -0.0964,  0.0374,  1.0931,  1.1897,  0.3133,  3.0390,  0.3465,\n",
      "         0.2444,  0.2688, -0.1778,  0.2684,  0.3559, -0.0887,  0.3948, -0.1205,\n",
      "        -0.7995,  0.6493,  0.0551, -0.4865,  0.2893,  0.6627,  0.1915, -1.1363,\n",
      "        -0.1140, -0.5977])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8648, -12.8436, -12.8545,  ..., -12.8804, -12.6952, -12.7744]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "lauterecken\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(360.3328, grad_fn=<AddBackward0>)\n",
      "tensor([ 8.1544e-01,  3.0171e-01,  5.4720e-01,  4.6581e-01,  2.8531e-01,\n",
      "        -5.6112e-01, -4.3913e-01, -9.0877e-03,  1.0002e-01, -1.7218e-01,\n",
      "         2.8133e-01,  3.7672e-01, -4.0756e-01,  1.5836e-01,  8.9113e-01,\n",
      "         1.2997e+00,  5.1508e-01, -1.9480e-01,  5.1856e-02, -9.3380e-01,\n",
      "         6.9955e-02, -2.4876e-01, -1.6723e-02, -2.0310e-01, -3.3558e-02,\n",
      "        -1.8132e+00,  1.1199e-01, -3.1961e-01, -1.3746e-01, -4.5499e-01,\n",
      "         3.8856e+00,  1.2140e+00, -1.0046e+00, -5.6274e-02,  3.8776e-03,\n",
      "        -4.0669e-01,  2.9452e-01,  3.0171e-01,  3.8848e-02, -5.6088e-01,\n",
      "        -4.6582e-01,  1.7155e-01,  3.3729e-01, -1.5247e-01,  2.3771e-02,\n",
      "         5.1415e-01, -2.1759e-01,  3.1965e-01, -3.4741e-01,  4.1672e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8892, -12.8933, -12.8585,  ..., -12.9879, -12.8332, -12.8102]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "standards-based\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(373.3088, grad_fn=<AddBackward0>)\n",
      "tensor([ 9.1102e-01, -2.2872e-01,  2.0770e-01, -2.0237e-01,  5.0697e-01,\n",
      "        -5.7893e-02, -4.1729e-01, -7.5341e-02, -3.0454e-01, -3.2860e-03,\n",
      "         4.4481e-01,  4.1818e-01, -3.3409e-01,  3.2917e-02,  9.8872e-01,\n",
      "         9.1984e-01,  4.0521e-01,  1.9250e-02, -1.0520e-01, -7.9865e-01,\n",
      "        -3.6403e-01, -8.7995e-02,  7.2182e-01,  1.1114e-01,  2.1530e-01,\n",
      "        -1.9411e+00, -2.6376e-01,  4.4550e-01,  2.7586e-01, -2.1104e-01,\n",
      "         4.0212e+00, -6.1943e-02, -3.2134e-01, -8.1922e-01,  2.1080e-01,\n",
      "        -2.0414e-01,  7.2625e-01,  4.7517e-01, -3.9853e-01, -3.9168e-01,\n",
      "        -3.4581e-01,  2.5928e-02,  1.3072e-01,  7.3562e-01, -1.5199e-01,\n",
      "        -1.8439e-01, -6.7128e-01,  1.6692e-01, -5.0063e-02,  1.9241e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.7987, -12.8922, -12.9057,  ..., -12.9795, -12.8589, -12.8936]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "modabber\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(386.0980, grad_fn=<AddBackward0>)\n",
      "tensor([-1.2758e-01,  6.3400e-03, -4.1712e-01, -4.0872e-01, -1.4783e-01,\n",
      "         2.4152e-01, -7.3754e-01,  6.3143e-02, -6.0675e-01,  8.3000e-02,\n",
      "        -2.1940e-01,  7.8223e-02, -2.7765e-01,  6.0430e-01,  7.8671e-01,\n",
      "        -2.4420e-01, -5.1904e-01, -2.2198e-01, -3.8463e-01, -2.9659e-01,\n",
      "         3.0544e-01,  2.7419e-01,  1.1790e+00,  7.4396e-01, -2.2553e-01,\n",
      "        -6.5778e-01, -4.7032e-01,  4.5433e-01, -1.8491e-01,  8.7581e-02,\n",
      "         2.0002e+00,  1.3517e-01,  6.0315e-01, -1.2642e+00, -3.0328e-01,\n",
      "         2.4517e-01,  1.8794e-01,  2.1194e-01, -1.3199e+00, -8.0437e-01,\n",
      "        -4.3518e-02,  1.4564e-01, -5.5825e-01, -1.3591e-03, -1.4056e-02,\n",
      "        -4.4587e-03, -3.1234e-01, -4.6868e-01, -2.2926e-01,  1.9415e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8516, -12.9476, -12.8077,  ..., -12.9151, -12.9452, -12.7734]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "zauberflöte\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(399.0877, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.2562,  0.4369, -0.1189,  0.2034,  0.4196,  0.8586, -0.6034, -0.3183,\n",
      "        -0.6718,  0.0040, -0.0752,  0.1104, -0.7353,  0.2744,  0.0540, -0.2383,\n",
      "        -0.1377,  0.0116, -0.4662, -0.5523,  0.0833,  0.5594,  0.5190, -0.2706,\n",
      "        -0.2821, -1.3918,  0.1750,  0.2659,  0.0614, -0.2730,  3.9032,  0.3817,\n",
      "        -0.0560, -0.0044,  0.2403,  0.3067, -0.1264,  0.3344,  0.0755, -0.0362,\n",
      "         0.1369,  0.3776, -0.1216, -0.1381,  0.1951,  0.2279, -0.1730, -0.0757,\n",
      "        -0.2587, -0.3934])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8649, -12.9552, -12.7874,  ..., -12.9508, -12.8931, -12.8106]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "cdr\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(411.9453, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6439,  0.2881,  0.3442, -0.3522,  0.7263,  0.0385, -0.1779,  0.5626,\n",
      "        -0.1008,  0.1060, -1.0243,  0.2986,  0.1191, -0.1778,  0.6216, -0.2908,\n",
      "        -0.2101, -0.5672,  0.9315, -0.7724, -0.1011,  0.8585,  0.8082,  0.3243,\n",
      "         1.3871, -1.0548, -0.5526,  0.0412, -0.0356, -0.5747,  1.8623, -0.1634,\n",
      "        -0.4344, -0.6757,  0.3490, -0.2392,  0.1474,  0.1238,  0.0563, -0.6694,\n",
      "         0.7579, -0.1132,  0.0764,  0.9069,  0.0960,  0.1821,  0.6267,  1.5925,\n",
      "         0.1784,  0.4551])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.9705, -12.8904, -12.7972,  ..., -12.9442, -12.8771, -12.8198]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "villeroi\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(425.0507, grad_fn=<AddBackward0>)\n",
      "tensor([ 0.6805, -0.0393,  0.3019, -0.1779,  0.4296,  0.0322, -0.4138,  0.1323,\n",
      "        -0.2985, -0.0853,  0.1712,  0.2242, -0.1005, -0.4365,  0.3342,  0.6785,\n",
      "         0.0572, -0.3445, -0.4279, -0.4327,  0.5596,  0.1003,  0.1868, -0.2685,\n",
      "         0.0373, -2.0932,  0.2217, -0.3987,  0.2091, -0.5573,  3.8826,  0.4747,\n",
      "        -0.9566, -0.3779,  0.2087, -0.3275,  0.1275,  0.0884,  0.1635, -0.2163,\n",
      "        -0.0944,  0.0183,  0.2105, -0.0309, -0.1972,  0.0823, -0.0943, -0.0733,\n",
      "        -0.0647, -0.2604])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.9250, -12.7473, -12.8954,  ..., -12.8035, -12.9584, -12.7546]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "tools\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(438.0126, grad_fn=<AddBackward0>)\n",
      "tensor([-0.0292,  0.8177,  0.3847, -0.7786,  1.1049, -0.1365, -0.0247, -0.0511,\n",
      "         0.7795,  0.0514, -0.3575,  1.1748, -0.0982,  0.3311,  0.4043,  0.5868,\n",
      "        -0.6254,  0.0948,  0.9702, -1.1437,  0.1383,  0.2814,  0.4669,  0.3523,\n",
      "         0.6892, -1.9819, -1.4000,  0.1700,  1.5929, -1.0086,  3.6499,  1.3949,\n",
      "        -0.7882,  0.4040, -0.3692,  0.7308,  0.0275, -0.1199,  0.7372, -1.0365,\n",
      "         0.6866, -0.3029, -0.5518,  0.9647,  0.0531, -0.0848,  0.8512, -0.5419,\n",
      "         0.3245,  0.5842])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8211, -12.7715, -12.9170,  ..., -12.7554, -12.8650, -12.8669]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "bonaiuti\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(451.1590, grad_fn=<AddBackward0>)\n",
      "tensor([ 3.3409e-01,  4.1048e-01,  9.7718e-02,  1.8240e-01,  3.7572e-01,\n",
      "         1.9732e-01, -1.8201e-03,  2.6661e-01, -2.1768e-01, -6.0361e-01,\n",
      "        -1.4803e+00,  3.0302e-01, -4.2344e-01,  1.1002e-01,  8.2706e-01,\n",
      "        -1.4026e-01, -5.5799e-01, -7.6903e-01,  5.6132e-01, -9.1551e-01,\n",
      "         4.8063e-01,  8.0385e-01,  7.6070e-01,  1.8617e-01,  1.1174e+00,\n",
      "        -1.8839e+00, -8.1789e-03,  1.2844e-02, -1.1430e-01, -1.6558e-01,\n",
      "         2.5268e+00,  6.8262e-02, -2.3514e-01, -1.3838e+00, -3.1208e-01,\n",
      "        -2.8143e-01, -4.5106e-01, -1.3011e-01, -1.4400e-01, -2.6303e-01,\n",
      "         2.0992e-01,  2.8024e-01,  1.9878e-01,  1.2869e+00,  1.4261e-01,\n",
      "         4.0745e-01,  5.0800e-01,  1.4671e+00, -1.1831e-01,  2.3719e-01])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8335, -12.8141, -12.9312,  ..., -12.8677, -12.8769, -13.0261]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "marshman\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(463.8643, grad_fn=<AddBackward0>)\n",
      "tensor([-0.3090,  0.1448,  1.1682, -0.5410, -0.4918, -1.3069,  0.8648, -1.7525,\n",
      "        -0.4348,  0.7152,  0.5256,  0.3003, -0.1692,  0.7859, -0.5247,  0.5646,\n",
      "        -1.4782,  0.6159, -0.9725,  0.5772, -0.8485,  1.1488, -0.2502,  0.2469,\n",
      "        -0.1474,  0.6831, -0.0678, -0.8064, -0.8093,  0.8649,  0.1110,  0.0237,\n",
      "        -0.1328,  1.3980, -0.7833, -0.7813,  0.9904, -1.2237,  0.2901, -0.0359,\n",
      "         1.5524, -0.3259,  0.5623,  1.6823, -0.3494,  1.5384, -0.1013, -0.4097,\n",
      "        -0.4651, -0.2958])\n",
      "torch.Size([1, 402650])\n",
      "tensor([[-12.8172, -12.7649, -12.8245,  ..., -12.8606, -12.8899, -12.9864]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "mousavian\n",
      "torch.int64\n",
      "torch.int64\n",
      "tensor(476.6293, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tpair = training_pairs[0]\n",
    "inp = tpair[0]\n",
    "tar = tpair[1]\n",
    "inp_size = inp.size(0)\n",
    "tar_size = tar.size(0)\n",
    "hidden_dim = 50\n",
    "# print(tar_size)\n",
    "\n",
    "# print(inp[0])\n",
    "\n",
    "# print(vocab.n_words)\n",
    "\n",
    "encoder = EncoderRNN(vocab.n_words,50)\n",
    "encoder_hidden = encoder.initHidden()\n",
    "encoder_outputs = torch.zeros(inp_size,hidden_size, device=device)\n",
    "\n",
    "\n",
    "for i in range(inp_size):\n",
    "   \n",
    "    encoder_output, encoder_hidden = encoder(inp[i], encoder_hidden)\n",
    "    encoder_outputs[i] = encoder_output[0, 0]\n",
    "    \n",
    "\n",
    "# print(encoder_outputs.shape)\n",
    "\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "#print(decoder_input)\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "# print(encoder_hidden[1].shape)\n",
    "\n",
    "decoder = DecoderRNN(hidden_size,vocab.n_words)\n",
    "loss  = 0\n",
    "criterion = nn.NLLLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(tar_size):\n",
    "    decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "    \n",
    "    # print(decoder_output.view(-1).shape)\n",
    "    # print(tar[i].shape)\n",
    "    # print(weight_matrix[tar[i].item()].view(-1).shape)\n",
    "    tar_tens = weight_matrix[tar[i].item()].view(-1).float()\n",
    "    # print(tar_tens.shape)\n",
    "    print(tar_tens)\n",
    "    # print(tar_tens.type())\n",
    "    # print(decoder_output.type())\n",
    "    # print(tar_tens)\n",
    "    print(decoder_output.shape)\n",
    "    print(decoder_output)\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    print(vocab.index2word[topi.item()])\n",
    "    print(topi.dtype)\n",
    "    print(tar[i].dtype) \n",
    "    loss += criterion(decoder_output,tar[i])\n",
    "    print(loss)\n",
    "    \n",
    "    decoder_input = tar[i]  # Teacher forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mousavian'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, ind = decoder_output.data.topk(1)\n",
    "lll = ind.item()\n",
    "print(lll)\n",
    "vocab.index2word[lll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "[ 6.1850e-01  6.4254e-01 -4.6552e-01  3.7570e-01  7.4838e-01  5.3739e-01\n",
      "  2.2239e-03 -6.0577e-01  2.6408e-01  1.1703e-01  4.3722e-01  2.0092e-01\n",
      " -5.7859e-02 -3.4589e-01  2.1664e-01  5.8573e-01  5.3919e-01  6.9490e-01\n",
      " -1.5618e-01  5.5830e-02 -6.0515e-01 -2.8997e-01 -2.5594e-02  5.5593e-01\n",
      "  2.5356e-01 -1.9612e+00 -5.1381e-01  6.9096e-01  6.6246e-02 -5.4224e-02\n",
      "  3.7871e+00 -7.7403e-01 -1.2689e-01 -5.1465e-01  6.6705e-02 -3.2933e-01\n",
      "  1.3483e-01  1.9049e-01  1.3812e-01 -2.1503e-01 -1.6573e-02  3.1200e-01\n",
      " -3.3189e-01 -2.6001e-02 -3.8203e-01  1.9403e-01 -1.2466e-01 -2.7557e-01\n",
      "  3.0899e-01  4.8497e-01]\n",
      "tensor([ 6.1850e-01,  6.4254e-01, -4.6552e-01,  3.7570e-01,  7.4838e-01,\n",
      "         5.3739e-01,  2.2239e-03, -6.0577e-01,  2.6408e-01,  1.1703e-01,\n",
      "         4.3722e-01,  2.0092e-01, -5.7859e-02, -3.4589e-01,  2.1664e-01,\n",
      "         5.8573e-01,  5.3919e-01,  6.9490e-01, -1.5618e-01,  5.5830e-02,\n",
      "        -6.0515e-01, -2.8997e-01, -2.5594e-02,  5.5593e-01,  2.5356e-01,\n",
      "        -1.9612e+00, -5.1381e-01,  6.9096e-01,  6.6246e-02, -5.4224e-02,\n",
      "         3.7871e+00, -7.7403e-01, -1.2689e-01, -5.1465e-01,  6.6705e-02,\n",
      "        -3.2933e-01,  1.3483e-01,  1.9049e-01,  1.3812e-01, -2.1503e-01,\n",
      "        -1.6573e-02,  3.1200e-01, -3.3189e-01, -2.6001e-02, -3.8203e-01,\n",
      "         1.9403e-01, -1.2466e-01, -2.7557e-01,  3.0899e-01,  4.8497e-01],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([1, 1, 50])\n",
      "402650\n",
      "14\n",
      "tensor([ 6.1850e-01,  6.4254e-01, -4.6552e-01,  3.7570e-01,  7.4838e-01,\n",
      "         5.3739e-01,  2.2239e-03, -6.0577e-01,  2.6408e-01,  1.1703e-01,\n",
      "         4.3722e-01,  2.0092e-01, -5.7859e-02, -3.4589e-01,  2.1664e-01,\n",
      "         5.8573e-01,  5.3919e-01,  6.9490e-01, -1.5618e-01,  5.5830e-02,\n",
      "        -6.0515e-01, -2.8997e-01, -2.5594e-02,  5.5593e-01,  2.5356e-01,\n",
      "        -1.9612e+00, -5.1381e-01,  6.9096e-01,  6.6246e-02, -5.4224e-02,\n",
      "         3.7871e+00, -7.7403e-01, -1.2689e-01, -5.1465e-01,  6.6705e-02,\n",
      "        -3.2933e-01,  1.3483e-01,  1.9049e-01,  1.3812e-01, -2.1503e-01,\n",
      "        -1.6573e-02,  3.1200e-01, -3.3189e-01, -2.6001e-02, -3.8203e-01,\n",
      "         1.9403e-01, -1.2466e-01, -2.7557e-01,  3.0899e-01,  4.8497e-01],\n",
      "       dtype=torch.float64)\n",
      "is\n",
      "tensor([[[-1.3822, -0.6749, -0.6311,  1.2387,  1.5750,  1.0151,  1.2894,\n",
      "          -0.9171, -0.5514, -1.3709,  0.2871, -0.9952,  0.7815,  0.4339,\n",
      "           0.1885, -0.6414, -0.3296,  0.0194,  0.3237, -0.9546,  1.5039,\n",
      "          -1.1855,  0.0678, -0.7975,  0.4584, -0.0877,  0.3946,  0.5069,\n",
      "          -1.2041, -1.1234,  1.1042,  0.9070, -1.4847, -1.0384,  0.3362,\n",
      "          -2.0734,  0.9875,  0.5441, -1.4019,  0.4111, -1.5377, -0.0220,\n",
      "          -0.8130,  0.9112, -0.1790,  1.9700,  1.0599, -2.0470, -0.0796,\n",
      "           0.5643]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 1, 50])\n",
      "torch.Size([1, 1, 50])\n",
      "tensor([ 0.0046,  0.0114,  0.0896, -0.0076,  0.0422, -0.0342,  0.0413, -0.0646,\n",
      "        -0.0404, -0.0490,  0.0170,  0.0459, -0.0620,  0.0821, -0.0209,  0.0920,\n",
      "         0.0025,  0.0683,  0.0016,  0.0053, -0.0610, -0.0152, -0.0517,  0.0535,\n",
      "         0.0761,  0.0773,  0.0113,  0.0890, -0.0816,  0.1463, -0.0768, -0.0113,\n",
      "        -0.0824, -0.0173, -0.0127,  0.0798,  0.0772, -0.0568, -0.1045, -0.0430,\n",
      "        -0.1028,  0.0581, -0.0806,  0.0611, -0.0116,  0.0292,  0.0359,  0.0706,\n",
      "        -0.0160,  0.0245], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_indx = inp[1].item()\n",
    "word = vocab.index2word[word_indx]\n",
    "print(word)\n",
    "print(vocab.glove[word])\n",
    "print(weight_matrix[word_indx])\n",
    "\n",
    "\n",
    "hidden = (torch.zeros(1, 1, 50),torch.zeros(1, 1, 50))\n",
    "print(hidden[0].shape)\n",
    "print(len(vocab.words))\n",
    "embedded = nn.Embedding(len(vocab.words),50)\n",
    "lstm = nn.LSTM(50,50)\n",
    "embedded.from_pretrained(weight_matrix)\n",
    "#lin = nn.Linear(hidden_size, tar_size)\n",
    "softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "print(inp[1].item())\n",
    "print(weight_matrix[inp[1].item()].view(-1))\n",
    "print(vocab.index2word[inp[1].item()])\n",
    "#print(vocab.glove['the'])\n",
    "out = embedded(inp[1]).view(1,1,-1)\n",
    "print(out)\n",
    "print(out.shape)\n",
    "out = F.relu(out)\n",
    "output, hidden = lstm(out, hidden)\n",
    "print(output.shape)\n",
    "#output = softmax(output[0])\n",
    "print(output.view(-1))\n",
    "\n",
    "\n",
    "\n",
    "# out = embedded(inp[1]).view(1,1,-1)\n",
    "# output, hidden = lstm(out, hidden)\n",
    "\n",
    "\n",
    "#print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63e72cdc82f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# please check what should be max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, sentence ,max_length=vocab.n_words, attn=False): # please check what should be max_length\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(vocab, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            if attn:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_attentions[di] = decoder_attention.data\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden) \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('sos')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(vocab.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        #print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0],attn=False)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "voc_size = len(vocab.words)\n",
    "hidden_dim = 50\n",
    "max_summary_size = 60\n",
    "encoder1 = EncoderRNN(vocab.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab.n_words).to(device)\n",
    "#attn_decoder1 = AttnDecoderRNN(hidden_size, vocab.n_words, dropout_p=0.1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638142099.979296\n",
      "encoder optimizer init\n",
      "decoder optimizer init\n",
      "choosing training pairs:1500\n",
      "init criterion\n",
      "starting iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bf4eeae73a45248262f73f86a94cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 41s (- 37m 43s) (100 6%) 11.7590\n",
      "5m 21s (- 34m 48s) (200 13%) 9.8065\n",
      "7m 49s (- 31m 16s) (300 20%) 9.1782\n",
      "10m 18s (- 28m 20s) (400 26%) 8.8418\n",
      "12m 46s (- 25m 32s) (500 33%) 8.6845\n",
      "15m 26s (- 23m 9s) (600 40%) 8.6397\n",
      "18m 5s (- 20m 40s) (700 46%) 8.5531\n",
      "20m 26s (- 17m 53s) (800 53%) 8.3687\n",
      "22m 56s (- 15m 17s) (900 60%) 8.4153\n",
      "25m 26s (- 12m 43s) (1000 66%) 8.1779\n",
      "27m 56s (- 10m 9s) (1100 73%) 8.1868\n",
      "30m 25s (- 7m 36s) (1200 80%) 7.9672\n",
      "32m 48s (- 5m 2s) (1300 86%) 8.0229\n",
      "35m 20s (- 2m 31s) (1400 93%) 8.0146\n",
      "37m 46s (- 0m 0s) (1500 100%) 7.9211\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 1500, print_every=100)\n",
    "\n",
    "# trainIters(encoder1, attn_decoder1,1000,True, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'AttnDecoderRNN' has no attribute 'encoder_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-ab3a50675f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(AttnDecoderRNN.embedded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(AttnDecoderRNN.embedded[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcatt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'AttnDecoderRNN' has no attribute 'encoder_outputs'"
     ]
    }
   ],
   "source": [
    "attn = nn.Linear(hidden_dim * 2, max_summary_len)\n",
    "# print(AttnDecoderRNN.embedded)\n",
    "# print(AttnDecoderRNN.embedded[0])\n",
    "print(AttnDecoderRNN.encoder_outputs.shape)\n",
    "catt = torch.cat((AttnDecoderRNN.embedded[0], AttnDecoderRNN.hidden[0].view(1,-1)),1)\n",
    "print(catt.shape)\n",
    "attn_weights  = F.softmax(attn(catt), dim=1)\n",
    "print(attn_weights.shape)\n",
    "print(attn_weights.unsqueeze(0).shape)\n",
    "print(encoder_outputs.shape)\n",
    "print(encoder_outputs.unsqueeze(0).shape)\n",
    "attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'encoder': encoder1,\n",
    "    'decoder': decoder1,\n",
    "    'vocab': vocab\n",
    "}\n",
    "\n",
    "with open(\"train_model.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(all_info_want_to_save, save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'EncoderRNN' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ae484de9b79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load the saved file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msaved_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# extract the information from the saved file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'EncoderRNN' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load the saved file\n",
    "with open('train_model.pkl','rb') as ff:\n",
    "    saved_info = pickle.load(ff)\n",
    "    \n",
    "# extract the information from the saved file\n",
    "encoder1 = saved_info['encoder']\n",
    "decoder1 = saved_info['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-445b3d75e531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder1' is not defined"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
