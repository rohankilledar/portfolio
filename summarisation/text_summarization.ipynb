{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "from os import listdir\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_file_name = 'unprocessed_file.pkl'\n",
    "cleaned_file_name ='cleaned_file.pkl'\n",
    "cnn = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/summarisation/cnn/stories\"\n",
    "path_of_downloaded_files = \"/Users/rohankilledar/Documents/MSc Artificial Intelligence/repos/Natural Language Processing/glove.6B.50d.txt\"\n",
    "filename = \"glove.6B.50d.txt\"\n",
    "embedding_dim = 50\n",
    "data_size = 25000\n",
    "hidden_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-0c6d93aa8805>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    }
   ],
   "source": [
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(filename)\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "print('loaded %s word vectors from %s.' % (len(word_vectors.key_to_index),filename ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "sos = 'sos'\n",
    "eos = 'eos'\n",
    "\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.words = []\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}\n",
    "        self.n_words = 0  # Count SOS and EOS\n",
    "        self.glove = {}\n",
    "        self.embedding_dim = word_vectors.get_vector('office').shape[0]\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in word_tokenize(sentence):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            self.words.append(word)\n",
    "            if word not in self.glove:\n",
    "                self.glove[word] = np.random.normal(scale=0.6 , size= (self.embedding_dim,))\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def addPretrained(self,path_of_downloaded_files):\n",
    "        with open(path_of_downloaded_files) as f:\n",
    "            for indx,l in enumerate(f):\n",
    "                line = l.split()\n",
    "                word = line[0]\n",
    "                if word == sos:\n",
    "                    first_word = self.words[0]\n",
    "                    self.words.append(first_word)\n",
    "                    self.words[0] = sos\n",
    "                    self.word2index[first_word] = indx\n",
    "                    self.word2index[sos] = 0\n",
    "                    self.index2word[indx] = first_word\n",
    "                    self.index2word[0] = sos\n",
    "                    self.glove[sos] = word_vectors[indx]\n",
    "                    self.glove[first_word] = word_vectors[0]\n",
    "                    self.word2count[sos] = 1\n",
    "                    self.n_words += 1\n",
    "\n",
    "                elif word == eos:\n",
    "                    sec_word = self.words[1]\n",
    "                    self.words.append(sec_word)\n",
    "                    self.words[1] = eos\n",
    "                    self.index2word[indx] = sec_word\n",
    "                    self.index2word[1] = eos\n",
    "                    self.word2index[sec_word] = indx\n",
    "                    self.word2index[eos] = 1\n",
    "                    self.glove[eos] = word_vectors[indx]\n",
    "                    self.glove[sec_word] = word_vectors[1]\n",
    "                    self.word2count[eos] = 1\n",
    "                    self.n_words += 1\n",
    "                else:\n",
    "                    self.words.append(word)\n",
    "                    self.word2count[word] = 1\n",
    "                    self.word2index[word] = indx\n",
    "                    self.index2word[indx]=word\n",
    "                    self.glove[word] = word_vectors[indx]\n",
    "                    self.n_words += 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase): \n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase) \n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)  \n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)  \n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)  \n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)  \n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)  \n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)  \n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)  \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    \n",
    "    \n",
    "    dash_indx = s.find('(CNN) --')\n",
    "    if dash_indx>=0: #and dash_indx<=20:\n",
    "        s = s[dash_indx+len('(CNN) --'):]\n",
    "        \n",
    "    s=decontracted(s)\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    file = open(filename, encoding= 'UTF-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def split_text(article):\n",
    "    indx = article.index('@highlight')\n",
    "    story = article[:indx]\n",
    "    highlight = article[indx:].split('@highlight')\n",
    "\n",
    "    highlight = \". \".join([h.strip() for h in highlight if len(h)>0])\n",
    "    return story,highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72374b47ca2f45ad8f1ef39998e70593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_all(folder):\n",
    "    dataset = list()\n",
    "\n",
    "    for file in tqdm(listdir(folder)):\n",
    "        filename = folder + '/' + file\n",
    "        article = read_file(filename)\n",
    "        story,highlight = split_text(article)\n",
    "\n",
    "        dataset.append({'story':story, 'highlight':highlight})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset = read_all(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving dataset for cleaning\n",
    "import pickle\n",
    "output_file = open(unprocessed_file_name,'wb')\n",
    "pickle.dump(dataset, output_file)\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_pickle(unprocessed_file_name)\n",
    "#reducing the dataset for initial testing of model\n",
    "dataset = dataset[:data_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['story'] = df['story'].apply(lambda x: normalizeString(x))\n",
    "df['highlight'] = df['highlight'].apply(lambda x: normalizeString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['highlight'] = df['highlight'].apply(lambda x: sos + \" \" + x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean word count length of text article is 689\n",
      "The mean word count length of summary/highlight is 46\n",
      "The max word count length of text article is 1884\n",
      "The max word count length of summary/highlight is 82\n"
     ]
    }
   ],
   "source": [
    "df['word_count_text'] = df['story'].apply(lambda x: len(str(x).split()))\n",
    "df['highlight_count'] = df['highlight'].apply(lambda x: len(str(x).split()))\n",
    "from math import floor\n",
    "print(\"The mean word count length of text article is \" + str(floor(df['word_count_text'].mean())))\n",
    "print(\"The mean word count length of summary/highlight is \" + str(floor(df['highlight_count'].mean())))\n",
    "\n",
    "max_article_len = floor(df['word_count_text'].max())\n",
    "max_summary_len = floor(df['highlight_count'].max())\n",
    "print(\"The max word count length of text article is \" + str(max_article_len))\n",
    "print(\"The max word count length of summary/highlight is \" + str(max_summary_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('word_count_text', axis=1, inplace=True)\n",
    "df.drop('highlight_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7e0562ce584608862583e4a10340fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counted Words:\n",
      "vocab 402650\n"
     ]
    }
   ],
   "source": [
    "vocab = Lang('vocab')\n",
    "vocab.addPretrained(path_of_downloaded_files)\n",
    "def prepareData():\n",
    "    for indx,row in tqdm(df.iterrows()):\n",
    "        vocab.addSentence(row['story'])\n",
    "        vocab.addSentence(row['highlight'])\n",
    "    print(\"counted Words:\")\n",
    "    print(vocab.name, vocab.n_words)\n",
    "prepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    # return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    return [lang.word2index[word] for word in word_tokenize(sentence)]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(vocab, pair[0])\n",
    "    target_tensor = tensorFromSentence(vocab, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_weights(unique_word_corpus,glove, tens=True):\n",
    "    matrix_len = len(unique_word_corpus)\n",
    "    unique_word2indx = {}\n",
    "    \n",
    "    weight_matrix  = np.zeros((matrix_len, embedding_dim))\n",
    "   \n",
    "    words_found = 0\n",
    "\n",
    "    for indx, word in enumerate(unique_word_corpus):\n",
    "        try:\n",
    "            unique_word2indx[word] = indx\n",
    "            weight_matrix[indx] = glove[word]\n",
    "            words_found +=1\n",
    "        except KeyError:\n",
    "            weight_matrix[indx] = np.random.normal(scale=0.6 , size= (embedding_dim,))\n",
    "            unique_word2indx[word] = indx\n",
    "    if tens:\n",
    "        return torch.from_numpy(weight_matrix) , unique_word2indx\n",
    "    else:\n",
    "        return weight_matrix,unique_word2indx\n",
    "\n",
    "weight_matrix, meh= generate_weights(vocab.words, vocab.glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5139, -0.7162, -0.2702,  ...,  0.1683,  0.5761,  0.0467],\n",
       "        [-0.3090,  0.1448,  1.1682,  ..., -0.4097, -0.4651, -0.2958],\n",
       "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
       "        ...,\n",
       "        [ 0.6183, -0.7022, -0.0809,  ...,  0.2502,  0.2620,  0.2695],\n",
       "        [ 1.3004, -0.1501,  0.6362,  ..., -0.0593, -0.4022, -0.8937],\n",
       "        [-0.0462, -0.2653,  0.0253,  ...,  0.0821,  0.0608, -0.4605]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51387 , -0.71619 , -0.27022 , -0.39605 ,  0.077725, -0.51019 ,\n",
       "       -0.096037, -0.51926 ,  1.1398  , -0.48839 ,  0.55519 , -0.079659,\n",
       "        0.63065 , -0.19989 , -0.72763 , -1.1698  , -0.78838 , -0.11933 ,\n",
       "       -0.016341,  0.58433 , -0.60493 ,  0.34394 , -0.10728 ,  0.38154 ,\n",
       "        0.60439 ,  0.098549, -0.62968 , -0.55329 , -0.40243 , -0.75822 ,\n",
       "        0.58165 ,  0.8636  , -0.80085 ,  0.26178 , -1.1834  ,  0.099697,\n",
       "        0.56937 , -1.6251  ,  0.4834  ,  0.36138 ,  0.73861 , -0.65523 ,\n",
       "       -0.31002 , -0.65169 ,  0.51786 ,  0.39711 ,  0.22438 ,  0.16832 ,\n",
       "        0.57609 ,  0.046694], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.glove['sos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28069\n",
      "tensor([28069])\n",
      "tensor([[ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "         -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "          2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "          1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "         -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "         -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "          4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "          7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "         -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "          1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01]],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "        -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "         2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "         1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "        -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "        -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "         4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "         7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "        -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "         1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "word = 'the'\n",
    "embeds = nn.Embedding(vocab.n_words, embedding_dim)  # 2 words in vocab, 5 dimensional embeddings\n",
    "embeds =embeds.from_pretrained(weight_matrix)\n",
    "lookup_tensor = torch.tensor([vocab.word2index[word]], dtype=torch.long)\n",
    "print(vocab.word2index[word])\n",
    "print(lookup_tensor)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n",
    "print(weight_matrix[vocab.word2index[word]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "<class 'torch.Tensor'>\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2,2)\n",
    "print(type(x))\n",
    "print(x.dtype)\n",
    "double_x = x.double()\n",
    "print(type(double_x))\n",
    "print(double_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "       # self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab.n_words, embedding_dim)\n",
    "        self.embedding = self.embedding.from_pretrained(weight_matrix)\n",
    "        #self.embedding.from_pretrained(glove)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "       # print(output)\n",
    "        #print(hidden)\n",
    "        output, hidden = self.lstm(output.float(), hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        #in case of LSTM we need h0 and c0 hence init this as a tuple (h0,c0) and passed as hidden to lstm and in case of gru its just h0\n",
    "       return (torch.zeros(1, 1, self.hidden_size, dtype=torch.float32, device=device), torch.zeros(1,1,self.hidden_size,dtype = torch.float32, device= device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding.from_pretrained(weight_matrix)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        #self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        #output = self.softmax(self.out(output[0]))\n",
    "        output = self.softmax(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, dtype = 'float32', device=device), torch.zeros(1,1,self.hidden_size,dtype = 'float32', device= device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_article_len):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "       \n",
    "        #print(embedded[0].shape)\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded, hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "                                 \n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "       return (torch.zeros(1, 1, self.hidden_size, dtype=torch.int64, device=device), torch.zeros(1,1,self.hidden_size,dtype = torch.int64, device= device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# def indexesFromSentence(lang, sentence):\n",
    "#     #return [lang.glove[word] for word in sentence.split(' ')]\n",
    "#     return [lang.word2index[word] for word in word_tokenize(sentence)]\n",
    "#     #return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_token)\n",
    "#     # indexes.append(lang.glove[eos])\n",
    "#     #change it to include glove values\n",
    "#     #return indexes\n",
    "#     return torch.Tensor(indexes,dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(vocab, pair[0])\n",
    "#     target_tensor = tensorFromSentence(vocab, pair[1])\n",
    "#     return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, attn, max_length=vocab.n_words):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if attn :\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden= decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "                tar_tens = weight_matrix[target_tensor[di].item()].view(-1).float()\n",
    "            loss += criterion(decoder_output.view(-1), tar_tens)\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            if attn :\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, decoder_hidden= decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            tar_tens = weight_matrix[target_tensor[di].item()].view(-1).float()\n",
    "            loss += criterion(decoder_output.view(-1), tar_tens)\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, attn=True, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print(start)\n",
    "\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    print('encoder optimizer init')\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    print('decoder optimizer init')\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    print('choosing training pairs:' + str(n_iters))\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    \n",
    "    print('init criterion')\n",
    "    # criterion = nn.NLLLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    print('starting iterations')\n",
    "    \n",
    "    for iter in tqdm(range(1, n_iters + 1)):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, attn)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                     for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = training_pairs[1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an\n",
      "``\n",
      "and\n",
      "and\n",
      "``\n",
      "he\n",
      "``\n",
      "-\n",
      "``\n",
      "at\n",
      "-\n",
      "-\n",
      "``\n",
      "he\n",
      "-\n",
      "-\n",
      "to\n",
      "he\n",
      "-\n",
      "will\n",
      "he\n",
      "he\n",
      "-\n",
      "-\n",
      "``\n",
      "-\n",
      "``\n",
      "-\n",
      "``\n",
      "``\n",
      "``\n",
      "he\n",
      "he\n",
      "which\n",
      "``\n",
      "will\n",
      "``\n",
      "he\n"
     ]
    }
   ],
   "source": [
    "tpair = training_pairs[0]\n",
    "inp = tpair[0]\n",
    "tar = tpair[1]\n",
    "inp_size = inp.size(0)\n",
    "tar_size = tar.size(0)\n",
    "hidden_dim = 50\n",
    "# print(tar_size)\n",
    "\n",
    "# print(inp[0])\n",
    "\n",
    "# print(vocab.n_words)\n",
    "\n",
    "encoder = EncoderRNN(vocab.n_words,50)\n",
    "encoder_hidden = encoder.initHidden()\n",
    "encoder_outputs = torch.zeros(inp_size,hidden_size, device=device)\n",
    "\n",
    "\n",
    "for i in range(inp_size):\n",
    "   \n",
    "    encoder_output, encoder_hidden = encoder(inp[i], encoder_hidden)\n",
    "\n",
    "    encoder_outputs[i] = encoder_output[0, 0]\n",
    "\n",
    "#print(encoder_outputs.shape)\n",
    "\n",
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "#print(decoder_input)\n",
    "decoder_hidden = encoder_hidden\n",
    "\n",
    "decoder = DecoderRNN(hidden_size,vocab.n_words)\n",
    "loss  = 0\n",
    "# criterion = nn.NLLLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in range(tar_size):\n",
    "    decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "    \n",
    "    # print(decoder_output.view(-1).shape)\n",
    "    # print(tar[i].shape)\n",
    "    # print(weight_matrix[tar[i].item()].view(-1).shape)\n",
    "    tar_tens = weight_matrix[tar[i].item()].view(-1).float()\n",
    "    # print(tar_tens.type())\n",
    "    # print(decoder_output.type())\n",
    "    # print(tar_tens)\n",
    "    # print(decoder_output)\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    print(vocab.index2word[topi.item()])\n",
    "    loss += criterion(decoder_output.view(-1),tar_tens )\n",
    "    \n",
    "    decoder_input = tar[i]  # Teacher forcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "henson\n",
      "[ 0.28302   -0.98354   -0.47318    0.97362    0.65512    0.65159\n",
      " -1.2712    -0.45614    0.28934    0.10817   -0.096854   1.2445\n",
      " -0.16026    0.077745   0.56126    0.072962   0.26976    0.29677\n",
      " -0.70432   -0.10092    0.10159    0.76659   -0.29101   -0.38968\n",
      "  0.61176    0.48632    0.74082   -0.39317   -0.56144   -1.1879\n",
      " -0.0040155 -0.24041    0.60474   -0.23765    0.012554   0.5866\n",
      "  0.22144   -0.67394    0.35473   -0.81246   -0.43274    0.1196\n",
      " -1.1431     0.03929   -0.057025   0.87628   -0.10193   -0.57598\n",
      " -0.42348    0.28004  ]\n",
      "tensor([ 0.2830, -0.9835, -0.4732,  0.9736,  0.6551,  0.6516, -1.2712, -0.4561,\n",
      "         0.2893,  0.1082, -0.0969,  1.2445, -0.1603,  0.0777,  0.5613,  0.0730,\n",
      "         0.2698,  0.2968, -0.7043, -0.1009,  0.1016,  0.7666, -0.2910, -0.3897,\n",
      "         0.6118,  0.4863,  0.7408, -0.3932, -0.5614, -1.1879, -0.0040, -0.2404,\n",
      "         0.6047, -0.2377,  0.0126,  0.5866,  0.2214, -0.6739,  0.3547, -0.8125,\n",
      "        -0.4327,  0.1196, -1.1431,  0.0393, -0.0570,  0.8763, -0.1019, -0.5760,\n",
      "        -0.4235,  0.2800], dtype=torch.float64)\n",
      "torch.Size([1, 1, 50])\n",
      "402650\n",
      "20121\n",
      "tensor([ 0.2830, -0.9835, -0.4732,  0.9736,  0.6551,  0.6516, -1.2712, -0.4561,\n",
      "         0.2893,  0.1082, -0.0969,  1.2445, -0.1603,  0.0777,  0.5613,  0.0730,\n",
      "         0.2698,  0.2968, -0.7043, -0.1009,  0.1016,  0.7666, -0.2910, -0.3897,\n",
      "         0.6118,  0.4863,  0.7408, -0.3932, -0.5614, -1.1879, -0.0040, -0.2404,\n",
      "         0.6047, -0.2377,  0.0126,  0.5866,  0.2214, -0.6739,  0.3547, -0.8125,\n",
      "        -0.4327,  0.1196, -1.1431,  0.0393, -0.0570,  0.8763, -0.1019, -0.5760,\n",
      "        -0.4235,  0.2800], dtype=torch.float64)\n",
      "henson\n",
      "tensor([[[ 1.0949, -1.0579, -1.2154,  0.7862,  0.6525, -0.7527, -0.5087,\n",
      "          -1.5705, -1.0404, -0.8598,  0.1828,  0.5518, -0.0567,  1.2532,\n",
      "          -0.8984, -0.6904,  0.6412, -0.0245,  0.4377, -0.8219,  0.6730,\n",
      "          -0.0100, -1.0147,  1.2025,  0.9649, -3.1571,  0.2363, -1.9611,\n",
      "          -0.1254, -0.9908,  1.0829,  0.1402, -3.9369, -0.5060, -0.4604,\n",
      "          -0.6164, -0.1409, -0.0241,  2.1378,  0.7071, -0.4702,  0.3902,\n",
      "          -0.1125,  0.9083,  0.4604, -1.3286,  1.6430, -1.1131,  0.4886,\n",
      "           1.4419]]], grad_fn=<ViewBackward0>)\n",
      "torch.Size([1, 1, 50])\n",
      "torch.Size([1, 1, 50])\n",
      "tensor([-0.0220,  0.0996, -0.0097,  0.1872,  0.0926, -0.1200, -0.1069, -0.2128,\n",
      "        -0.0342, -0.0333,  0.0394, -0.0752,  0.1621, -0.0036,  0.0455,  0.0521,\n",
      "         0.0998, -0.1633, -0.0373, -0.1236, -0.0482, -0.0569, -0.0147,  0.0321,\n",
      "        -0.0581,  0.1038,  0.0237, -0.0054, -0.0328,  0.1102,  0.1344,  0.0044,\n",
      "         0.0045, -0.0536, -0.0016, -0.1158,  0.0759, -0.0480,  0.1833,  0.1016,\n",
      "         0.0938,  0.0052, -0.2084,  0.0131, -0.0162,  0.0544, -0.0428,  0.0700,\n",
      "        -0.0126,  0.0949], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_indx = inp[1].item()\n",
    "word = vocab.index2word[word_indx]\n",
    "print(word)\n",
    "print(vocab.glove[word])\n",
    "print(weight_matrix[word_indx])\n",
    "\n",
    "\n",
    "hidden = (torch.zeros(1, 1, 50),torch.zeros(1, 1, 50))\n",
    "print(hidden[0].shape)\n",
    "print(len(vocab.words))\n",
    "embedded = nn.Embedding(len(vocab.words),50)\n",
    "lstm = nn.LSTM(50,50)\n",
    "embedded.from_pretrained(weight_matrix)\n",
    "#lin = nn.Linear(hidden_size, tar_size)\n",
    "softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "print(inp[1].item())\n",
    "print(weight_matrix[inp[1].item()].view(-1))\n",
    "print(vocab.index2word[inp[1].item()])\n",
    "#print(vocab.glove['the'])\n",
    "out = embedded(inp[1]).view(1,1,-1)\n",
    "print(out)\n",
    "print(out.shape)\n",
    "out = F.relu(out)\n",
    "output, hidden = lstm(out, hidden)\n",
    "print(output.shape)\n",
    "#output = softmax(output[0])\n",
    "print(output.view(-1))\n",
    "\n",
    "\n",
    "\n",
    "# out = embedded(inp[1]).view(1,1,-1)\n",
    "# output, hidden = lstm(out, hidden)\n",
    "\n",
    "\n",
    "#print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence ,max_length=vocab.n_words, attn=True): # please check what should be max_length\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(vocab, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            if attn:\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "                decoder_attentions[di] = decoder_attention.data\n",
    "            else:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden) \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(vocab.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0],attn=False)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-86dc7775ae60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvoc_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_summary_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_size = 50\n",
    "voc_size = len(vocab.words)\n",
    "hidden_dim = 50\n",
    "max_summary_size = 60\n",
    "encoder1 = EncoderRNN(vocab.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab.n_words).to(device)\n",
    "#attn_decoder1 = AttnDecoderRNN(hidden_size, vocab.n_words, dropout_p=0.1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638058551.026687\n",
      "encoder optimizer init\n",
      "decoder optimizer init\n",
      "choosing training pairs:1000\n",
      "init criterion\n",
      "starting iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7cd3c4f72b4c5c9e6f69f09f7b51dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 59s (- 18m 41s) (50 5%) 15.8081\n",
      "1m 48s (- 16m 16s) (100 10%) 15.8344\n",
      "2m 42s (- 15m 20s) (150 15%) 15.8172\n",
      "3m 34s (- 14m 19s) (200 20%) 15.8584\n",
      "4m 26s (- 13m 18s) (250 25%) 15.8079\n",
      "5m 13s (- 12m 11s) (300 30%) 15.7736\n",
      "6m 3s (- 11m 15s) (350 35%) 15.8388\n",
      "7m 0s (- 10m 31s) (400 40%) 15.8239\n",
      "8m 8s (- 9m 57s) (450 45%) 15.8137\n",
      "9m 17s (- 9m 17s) (500 50%) 15.8387\n",
      "10m 17s (- 8m 25s) (550 55%) 15.8460\n",
      "11m 19s (- 7m 32s) (600 60%) 15.8141\n",
      "12m 20s (- 6m 38s) (650 65%) 15.8584\n",
      "13m 19s (- 5m 42s) (700 70%) 15.8271\n",
      "14m 21s (- 4m 47s) (750 75%) 15.7761\n",
      "15m 29s (- 3m 52s) (800 80%) 15.8048\n",
      "16m 36s (- 2m 55s) (850 85%) 15.8359\n",
      "17m 48s (- 1m 58s) (900 90%) 15.8265\n",
      "18m 47s (- 0m 59s) (950 95%) 15.7865\n",
      "19m 55s (- 0m 0s) (1000 100%) 15.8070\n"
     ]
    }
   ],
   "source": [
    "#trainIters(encoder1, attn_decoder1, 4000, print_every=500)\n",
    "\n",
    "trainIters(encoder1, decoder1,20000,False, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and other necessary modules\n",
    "all_info_want_to_save = {\n",
    "    'encoder': encoder1,\n",
    "    'decoder': decoder1\n",
    "}\n",
    "\n",
    "with open(\"enc_dec.pkl\",\"wb\") as save_path:\n",
    "    pickle.dump(all_info_want_to_save, save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-445b3d75e531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder1' is not defined"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, decoder1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
